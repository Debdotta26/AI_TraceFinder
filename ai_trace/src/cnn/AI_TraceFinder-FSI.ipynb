{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6KHfEfa4m1o"
      },
      "source": [
        "                                        Preprocessing on Official and Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2qjolJixNQv",
        "outputId": "c4d00f55-0180-4789-f333-cc0af6251b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Preprocessing Official images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 3315.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Preprocessing Wikipedia images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:44<00:00,  4.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved Official+Wiki residuals (150 & 300 separately) to C://Users//ariji//Desktop//ai_trace//models//official_wiki_residuals.pkl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os, cv2, numpy as np, pickle\n",
        "from tqdm import tqdm\n",
        "import pywt\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Paths\n",
        "OFFICIAL_DIR = \"C://Users//ariji//Desktop//ai_trace//process_data//Official\"\n",
        "WIKI_DIR = \"C://Users//ariji//Desktop//ai_trace//process_data//Wikipedia\"\n",
        "OUT_PATH = \"C://Users//ariji//Desktop//ai_trace//models//official_wiki_residuals.pkl\"\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Preprocessing helpers\n",
        "# ---------------------------\n",
        "def to_gray(img):\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim == 3 else img\n",
        "\n",
        "def resize_to(img, size=(256,256)):\n",
        "    return cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "def normalize_img(img):\n",
        "    return img.astype(np.float32) / 255.0\n",
        "\n",
        "def denoise_wavelet(img):\n",
        "    coeffs = pywt.dwt2(img, 'haar')\n",
        "    cA, (cH, cV, cD) = coeffs\n",
        "    # Zero out detail coefficients for denoising\n",
        "    cH[:] = 0; cV[:] = 0; cD[:] = 0\n",
        "    return pywt.idwt2((cA,(cH,cV,cD)), 'haar')\n",
        "\n",
        "def compute_residual(img):\n",
        "    denoised = denoise_wavelet(img)\n",
        "    return img - denoised\n",
        "\n",
        "def process_single_image(fpath):\n",
        "    \"\"\"Preprocess one image and return residual\"\"\"\n",
        "    img = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        return None\n",
        "    gray = to_gray(img)\n",
        "    gray = resize_to(gray, (256,256))\n",
        "    gray = normalize_img(gray)\n",
        "    return compute_residual(gray)\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset Processing\n",
        "# ---------------------------\n",
        "def process_dataset(base_dir, dataset_name, residuals_dict):\n",
        "    print(f\"ðŸ”„ Preprocessing {dataset_name} images...\")\n",
        "\n",
        "    for scanner in tqdm(os.listdir(base_dir)):\n",
        "        scanner_path = os.path.join(base_dir, scanner)\n",
        "        if not os.path.isdir(scanner_path):\n",
        "            continue\n",
        "\n",
        "        residuals_dict[dataset_name][scanner] = {}\n",
        "\n",
        "        for dpi in os.listdir(scanner_path):   # 150, 300\n",
        "            dpi_path = os.path.join(scanner_path, dpi)\n",
        "            if not os.path.isdir(dpi_path):\n",
        "                continue\n",
        "\n",
        "            files = [os.path.join(dpi_path, f) for f in os.listdir(dpi_path)\n",
        "                     if f.lower().endswith(('.tif','.tiff','.jpg','.jpeg','.png'))]\n",
        "\n",
        "            dpi_residuals = []\n",
        "            # Parallel processing\n",
        "            with ThreadPoolExecutor(max_workers=8) as executor:  # adjust workers based on Colab\n",
        "                futures = [executor.submit(process_single_image, f) for f in files]\n",
        "                for fut in as_completed(futures):\n",
        "                    res = fut.result()\n",
        "                    if res is not None:\n",
        "                        dpi_residuals.append(res)\n",
        "\n",
        "            residuals_dict[dataset_name][scanner][dpi] = dpi_residuals\n",
        "\n",
        "# ---------------------------\n",
        "# Main Execution\n",
        "# ---------------------------\n",
        "residuals_dict = {\"Official\": {}, \"Wikipedia\": {}}\n",
        "\n",
        "process_dataset(OFFICIAL_DIR, \"Official\", residuals_dict)\n",
        "process_dataset(WIKI_DIR, \"Wikipedia\", residuals_dict)\n",
        "\n",
        "with open(OUT_PATH, \"wb\") as f:\n",
        "    pickle.dump(residuals_dict, f)\n",
        "\n",
        "print(f\"âœ… Saved Official+Wiki residuals (150 & 300 separately) to {OUT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lK5ryZN4sxc"
      },
      "source": [
        "                                                      Preprocessing on Flatfield"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4ThRJ_c4PpA",
        "outputId": "742cc44b-c7db-40bb-a50f-03333e7e2d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Found Flatfield folder: C://Users//ariji//Desktop//ai_trace//process_data\\Flatfield\n",
            "Will save residuals to: C://Users//ariji//Desktop//ai_trace//process_data\\flatfield_residuals.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scanners: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 17.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Done. Saved residuals for 11 scanners, 22 images.\n",
            "Example scanners: ['Canon120-1', 'Canon120-2', 'Canon220', 'Canon9000-1', 'Canon9000-2']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "import os, pickle, cv2, numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Auto-locate Flatfield folder\n",
        "# ---------------------------\n",
        "def find_flatfield(base=\"C://Users//ariji//Desktop//ai_trace//process_data\"):\n",
        "    found = []\n",
        "    for root, dirs, files in os.walk(base):\n",
        "        for d in dirs:\n",
        "            if d.lower() == \"flatfield\":   # case-insensitive search\n",
        "                found.append(os.path.join(root, d))\n",
        "    return found\n",
        "\n",
        "flatfield_paths = find_flatfield(\"C://Users//ariji//Desktop//ai_trace//process_data\")\n",
        "if not flatfield_paths:\n",
        "    raise FileNotFoundError(\"âŒ No 'Flatfield' folder found in your Drive. Please check dataset upload.\")\n",
        "else:\n",
        "    FLATFIELD_DIR = flatfield_paths[0]  # take the first match\n",
        "    BASE = os.path.dirname(FLATFIELD_DIR)\n",
        "    OUTPUT_PKL = os.path.join(BASE, \"flatfield_residuals.pkl\")\n",
        "    print(\"âœ… Found Flatfield folder:\", FLATFIELD_DIR)\n",
        "    print(\"Will save residuals to:\", OUTPUT_PKL)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Import denoising filters\n",
        "# ---------------------------\n",
        "try:\n",
        "    from skimage.restoration import denoise_wavelet\n",
        "except Exception:\n",
        "    !pip install scikit-image\n",
        "    from skimage.restoration import denoise_wavelet\n",
        "\n",
        "from scipy.signal import wiener as scipy_wiener\n",
        "\n",
        "# ---------------------------\n",
        "# 3) Parameters\n",
        "# ---------------------------\n",
        "IMG_SIZE = (256, 256)      # resize target\n",
        "DENOISE_METHOD = \"wavelet\"  # \"wiener\" or \"wavelet\"\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Preprocess function\n",
        "# ---------------------------\n",
        "def preprocess_image_residual(path, img_size=IMG_SIZE, method=\"wiener\"):\n",
        "    \"\"\"Read image -> grayscale -> resize -> normalize -> denoise -> return residual.\"\"\"\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        return None\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, img_size, interpolation=cv2.INTER_AREA)\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    if method == \"wiener\":\n",
        "        den = scipy_wiener(img, mysize=(5,5))\n",
        "    else:\n",
        "        den = denoise_wavelet(img, channel_axis=None, rescale_sigma=True)\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Process all Flatfield images\n",
        "# ---------------------------\n",
        "flatfield_residuals = {}\n",
        "scanners = sorted(os.listdir(FLATFIELD_DIR))\n",
        "\n",
        "for scanner in tqdm(scanners, desc=\"Scanners\"):\n",
        "    scanner_dir = os.path.join(FLATFIELD_DIR, scanner)\n",
        "    if not os.path.isdir(scanner_dir):\n",
        "        continue\n",
        "\n",
        "    residuals = []\n",
        "    for fname in sorted(os.listdir(scanner_dir)):\n",
        "        if fname.startswith(\"._\"):\n",
        "            continue\n",
        "        if not fname.lower().endswith((\".tif\", \".tiff\", \".png\", \".jpg\", \".jpeg\")):\n",
        "            continue\n",
        "        fpath = os.path.join(scanner_dir, fname)\n",
        "        try:\n",
        "            res = preprocess_image_residual(fpath, IMG_SIZE, DENOISE_METHOD)\n",
        "            if res is not None:\n",
        "                residuals.append(res)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Failed on {fpath}: {e}\")\n",
        "\n",
        "    if residuals:\n",
        "        flatfield_residuals[scanner] = residuals\n",
        "    else:\n",
        "        print(f\"âš ï¸ No valid images for scanner: {scanner}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Save results\n",
        "# ---------------------------\n",
        "with open(OUTPUT_PKL, \"wb\") as f:\n",
        "    pickle.dump(flatfield_residuals, f)\n",
        "\n",
        "# ---------------------------\n",
        "# 7) Summary\n",
        "# ---------------------------\n",
        "total_scanners = len(flatfield_residuals)\n",
        "total_images = sum(len(v) for v in flatfield_residuals.values())\n",
        "print(f\"\\nâœ… Done. Saved residuals for {total_scanners} scanners, {total_images} images.\")\n",
        "print(\"Example scanners:\", list(flatfield_residuals.keys())[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj8SvmUo2B8E"
      },
      "source": [
        "                                                              EDA Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgJO11642NRW"
      },
      "source": [
        "Counting the total images in dataset in a tabular form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuonLSyF2J5W",
        "outputId": "18dae971-f586-41cd-b261-3e177c635dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class: Flatfield\n",
            "+-----------------------+--------------------+\n",
            "| Subfolder             |   Number of Images |\n",
            "+=======================+====================+\n",
            "| Flatfield             |                  0 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\Canon120-1  |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\Canon120-2  |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\Canon220    |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\Canon9000-1 |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\Canon9000-2 |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\EpsonV370-1 |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\EpsonV370-2 |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\EpsonV39-1  |                  3 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\EpsonV39-2  |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\EpsonV550   |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "| Flatfield\\HP          |                  2 |\n",
            "+-----------------------+--------------------+\n",
            "Total images in class 'Flatfield': 23\n",
            "\n",
            "\n",
            "Class: Official\n",
            "+------------------------------------------+--------------------+\n",
            "| Subfolder                                |   Number of Images |\n",
            "+==========================================+====================+\n",
            "| Official                                 |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-1 (1)                  |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-1 (1)\\Canon120-1       |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-1 (1)\\Canon120-1\\150   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-1 (1)\\Canon120-1\\300   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-2 (1)                  |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-2 (1)\\Canon120-2       |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-2 (1)\\Canon120-2\\150   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon120-2 (1)\\Canon120-2\\300   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon220 (1)                    |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon220 (1)\\Canon220           |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon220 (1)\\Canon220\\150       |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon220 (1)\\Canon220\\300       |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-1 (1)                 |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-1 (1)\\Canon9000-1     |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-1 (1)\\Canon9000-1\\150 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-1 (1)\\Canon9000-1\\300 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-2 (1)                 |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-2 (1)\\Canon9000-2     |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-2 (1)\\Canon9000-2\\150 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\Canon9000-2 (1)\\Canon9000-2\\300 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-1 (1)                 |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-1 (1)\\EpsonV370-1     |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-1 (1)\\EpsonV370-1\\150 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-1 (1)\\EpsonV370-1\\300 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-2 (1)                 |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-2 (1)\\EpsonV370-2     |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-2 (1)\\EpsonV370-2\\150 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV370-2 (1)\\EpsonV370-2\\300 |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-1 (1)                  |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-1 (1)\\EpsonV39-1       |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-1 (1)\\EpsonV39-1\\150   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-1 (1)\\EpsonV39-1\\300   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-2 (1)                  |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-2 (1)\\EpsonV39-2       |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-2 (1)\\EpsonV39-2\\150   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV39-2 (1)\\EpsonV39-2\\300   |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV550 (1)                   |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV550 (1)\\EpsonV550         |                  0 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV550 (1)\\EpsonV550\\150     |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "| Official\\EpsonV550 (1)\\EpsonV550\\300     |                100 |\n",
            "+------------------------------------------+--------------------+\n",
            "Total images in class 'Official': 2000\n",
            "\n",
            "\n",
            "Class: Tampered images\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Subfolder                                                        |   Number of Images |\n",
            "+==================================================================+====================+\n",
            "| Tampered images                                                  |                  0 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images                                  |                  0 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Binary masks                     |                  0 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Binary masks\\Copy-move           |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Binary masks\\Retouching          |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Binary masks\\Splicing            |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Description                      |                  0 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Original                         |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Tampered                         |                  0 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Tampered\\Copy-move               |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Tampered\\Retouching              |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Tampered\\Splicing                |                 34 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "| Tampered images\\Tampered images\\Tampered\\Splicing\\external files |                  0 |\n",
            "+------------------------------------------------------------------+--------------------+\n",
            "Total images in class 'Tampered images': 238\n",
            "\n",
            "\n",
            "Class: Wikipedia\n",
            "+---------------------------+--------------------+\n",
            "| Subfolder                 |   Number of Images |\n",
            "+===========================+====================+\n",
            "| Wikipedia                 |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon120-1      |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon120-1\\150  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon120-1\\300  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon120-2      |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon120-2\\150  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon120-2\\300  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon220        |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon220\\150    |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon220\\300    |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon9000-1     |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon9000-1\\150 |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon9000-1\\300 |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon9000-2     |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon9000-2\\150 |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\Canon9000-2\\300 |                 99 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV370-1     |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV370-1\\150 |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV370-1\\300 |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV370-2     |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV370-2\\150 |                109 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV370-2\\300 |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV39-1      |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV39-1\\150  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV39-1\\300  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV39-2      |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV39-2\\150  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV39-2\\300  |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV550       |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV550\\150   |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\EpsonV550\\300   |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\HP              |                  0 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\HP\\150          |                108 |\n",
            "+---------------------------+--------------------+\n",
            "| Wikipedia\\HP\\300          |                108 |\n",
            "+---------------------------+--------------------+\n",
            "Total images in class 'Wikipedia': 2368\n",
            "\n",
            "Total images in dataset: 4629\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "({'Flatfield': 23,\n",
              "  'Official': 2000,\n",
              "  'Tampered images': 238,\n",
              "  'Wikipedia': 2368},\n",
              " 4629)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from tabulate import tabulate\n",
        "\n",
        "def count_images_tif(dataset_path, extensions=None):\n",
        "    if extensions is None:\n",
        "        # Include .tif images\n",
        "        extensions = {\".tif\"}\n",
        "\n",
        "    class_counts = {}\n",
        "    total_images = 0\n",
        "\n",
        "    for class_name in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            subfolder_counts = {}\n",
        "            class_total = 0\n",
        "            # Walk recursively through all subfolders\n",
        "            for root, dirs, files in os.walk(class_path):\n",
        "                sub_count = sum(1 for f in files if os.path.splitext(f)[1].lower() in extensions)\n",
        "                subfolder_name = os.path.relpath(root, dataset_path)\n",
        "                subfolder_counts[subfolder_name] = sub_count\n",
        "                class_total += sub_count\n",
        "\n",
        "            # Print table for this class\n",
        "            print(f\"\\nClass: {class_name}\")\n",
        "            table = [[sub, cnt] for sub, cnt in subfolder_counts.items()]\n",
        "            print(tabulate(table, headers=[\"Subfolder\", \"Number of Images\"], tablefmt=\"grid\"))\n",
        "            print(f\"Total images in class '{class_name}': {class_total}\\n\")\n",
        "\n",
        "            class_counts[class_name] = class_total\n",
        "            total_images += class_total\n",
        "\n",
        "    print(f\"Total images in dataset: {total_images}\")\n",
        "    return class_counts, total_images\n",
        "\n",
        "# Set your dataset path\n",
        "dataset_path = \"C://Users//ariji//Desktop//ai_trace//process_data\"\n",
        "count_images_tif(dataset_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjG7HGPK2ivw"
      },
      "source": [
        "Checking for corrupted Images in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTxN4UiM2jiS",
        "outputId": "c2f021d6-94a9-420c-860e-73b630975e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total corrupted files found: 1\n",
            "C://Users//ariji//Desktop//ai_trace//process_data\\Flatfield\\EpsonV39-1\\._150.tif\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Paths\n",
        "dataset_path = \"C://Users//ariji//Desktop//ai_trace//process_data\"\n",
        "extensions = {\".tif\"}\n",
        "\n",
        "corrupted_files = []\n",
        "\n",
        "# Walk through entire dataset\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        if os.path.splitext(file)[1].lower() in extensions:\n",
        "            file_path = os.path.join(root, file)\n",
        "            img = cv2.imread(file_path)\n",
        "            if img is None:\n",
        "                corrupted_files.append(file_path)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Total corrupted files found: {len(corrupted_files)}\")\n",
        "if len(corrupted_files) > 0:\n",
        "    for f in corrupted_files:\n",
        "        print(f)\n",
        "else:\n",
        "    print(\"No corrupted images found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL097lSeB0PT"
      },
      "source": [
        "                                      Build Fingerprints from Flat-field Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llt6wQ6gQVJF",
        "outputId": "8ed58457-5ed2-43e9-97fa-959f2d3671ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing fingerprints from Flatfields...\n",
            "Extracted 11 scanner fingerprints.\n",
            "Saved scanner fingerprints to C://Users//ariji//Desktop//ai_trace//models//scanner_fingerprints.pkl\n",
            "Saved fp_keys.npy with order: ['Canon120-1', 'Canon120-2', 'Canon220', 'Canon9000-1', 'Canon9000-2', 'EpsonV370-1', 'EpsonV370-2', 'EpsonV39-1', 'EpsonV39-2', 'EpsonV550', 'HP']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Paths\n",
        "FLATFIELD_RESIDUALS_PATH = \"C://Users//ariji//Desktop//ai_trace//process_data//flatfield_residuals.pkl\"\n",
        "FP_OUT_PATH = \"C://Users//ariji//Desktop//ai_trace//models//scanner_fingerprints.pkl\"\n",
        "ORDER_NPY = \"C://Users//ariji//Desktop//ai_trace//models//fp_keys.npy\"\n",
        "\n",
        "# Load residuals\n",
        "if not os.path.exists(FLATFIELD_RESIDUALS_PATH):\n",
        "    raise FileNotFoundError(f\"Missing file: {FLATFIELD_RESIDUALS_PATH}\")\n",
        "\n",
        "with open(FLATFIELD_RESIDUALS_PATH, \"rb\") as f:\n",
        "    flatfield_residuals = pickle.load(f)\n",
        "\n",
        "# Compute fingerprint per scanner\n",
        "scanner_fingerprints = {}\n",
        "print(\"Computing fingerprints from Flatfields...\")\n",
        "for scanner, residuals in flatfield_residuals.items():\n",
        "    if not residuals:\n",
        "        continue\n",
        "    stack = np.stack(residuals, axis=0)       # (num_images, H, W)\n",
        "    fingerprint = np.mean(stack, axis=0)       # average residual\n",
        "    scanner_fingerprints[scanner] = fingerprint\n",
        "\n",
        "print(f\"Extracted {len(scanner_fingerprints)} scanner fingerprints.\")\n",
        "\n",
        "# Save fingerprints\n",
        "with open(FP_OUT_PATH, \"wb\") as f:\n",
        "    pickle.dump(scanner_fingerprints, f)\n",
        "print(f\"Saved scanner fingerprints to {FP_OUT_PATH}\")\n",
        "\n",
        "# Save a stable, deterministic order for scanners\n",
        "fp_keys = sorted(scanner_fingerprints.keys())\n",
        "np.save(ORDER_NPY, np.array(fp_keys))\n",
        "print(\"Saved fp_keys.npy with order:\", fp_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxLg6rUwCEpK"
      },
      "source": [
        "                                          Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCclr2dHCIx1",
        "outputId": "7f37f5da-3f99-4c0a-b289-e60adc47a3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded fingerprints and key order. Keys: ['Canon120-1', 'Canon120-2', 'Canon220', 'Canon9000-1', 'Canon9000-2', 'EpsonV370-1', 'EpsonV370-2', 'EpsonV39-1', 'EpsonV39-2', 'EpsonV550', 'HP']\n",
            " Loaded residuals for datasets: ['Official', 'Wikipedia']\n",
            " Computing features for Official ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 102.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Computing features for Wikipedia ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:06<00:00,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Saved features + labels to C://Users//ariji//Desktop//ai_trace//models//features.pkl\n",
            "Shape: (2368, 11)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pickle, numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "FP_PATH = \"C://Users//ariji//Desktop//ai_trace//models//scanner_fingerprints.pkl\"\n",
        "ORDER_NPY = \"C://Users//ariji//Desktop//ai_trace//models//fp_keys.npy\"\n",
        "\n",
        "RES_PATH = \"C://Users//ariji//Desktop//ai_trace//models//official_wiki_residuals.pkl\"\n",
        "OUT_PATH = \"C://Users//ariji//Desktop//ai_trace//models//features.pkl\"\n",
        "# Load fingerprints and fixed order\n",
        "with open(FP_PATH, \"rb\") as f:\n",
        "    scanner_fps = pickle.load(f)\n",
        "fp_keys = np.load(ORDER_NPY, allow_pickle=True).tolist()\n",
        "print(\" Loaded fingerprints and key order. Keys:\", fp_keys)\n",
        "\n",
        "# Helper: normalized cross-correlation (zero-mean cosine similarity)\n",
        "def corr2d(a, b):\n",
        "    a = a.astype(np.float32).ravel()\n",
        "    b = b.astype(np.float32).ravel()\n",
        "    a -= a.mean()\n",
        "    b -= b.mean()\n",
        "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    return float((a @ b) / denom) if denom != 0 else 0.0\n",
        "# ZNCC equals the dot product of zero-mean, unit-norm vectors, i.e., cosine similarity in L2 space. [web:188][web:189][web:169]\n",
        "\n",
        "# Load residuals (already precomputed; do not preprocess again)\n",
        "with open(RES_PATH, \"rb\") as f:\n",
        "    residuals_dict = pickle.load(f)\n",
        "print(\" Loaded residuals for datasets:\", list(residuals_dict.keys()))\n",
        "\n",
        "# Build features in the exact fp_keys order\n",
        "features, labels = [], []\n",
        "for dataset_name in [\"Official\", \"Wikipedia\"]:\n",
        "    print(f\" Computing features for {dataset_name} ...\")\n",
        "    for scanner, dpi_dict in tqdm(residuals_dict[dataset_name].items()):\n",
        "        for dpi, res_list in dpi_dict.items():\n",
        "            for res in res_list:\n",
        "                vec = [corr2d(res, scanner_fps[k]) for k in fp_keys]\n",
        "                features.append(vec)\n",
        "                labels.append(scanner)\n",
        "\n",
        "# Save features + labels\n",
        "with open(OUT_PATH, \"wb\") as f:\n",
        "    pickle.dump({\"features\": features, \"labels\": labels}, f)\n",
        "print(f\" Saved features + labels to {OUT_PATH}\")\n",
        "print(\"Shape:\", (len(features), len(features[0]) if features else 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyOSgN6nSO8k",
        "outputId": "ef4396d9-2092-45f1-9b43-d352767701b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”„ Extracting enhanced features (FFT + LBP + Texture)...\n",
            "Processing Official...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 629.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Wikipedia...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/11 [00:00<?, ?it/s]C:\\Users\\ariji\\AppData\\Roaming\\Python\\Python312\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
            "  warnings.warn(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [01:47<00:00,  9.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Enhanced features shape: 2368 x 33\n",
            "âœ… Saved to C://Users//ariji//Desktop//ai_trace//models//enhanced_features.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# Enhanced Feature Extraction (FFT + LBP + Texture)\n",
        "# ==============================\n",
        "import pickle, numpy as np\n",
        "from tqdm import tqdm\n",
        "from skimage.feature import local_binary_pattern\n",
        "from scipy import ndimage\n",
        "from scipy.fft import fft2, fftshift\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load existing residuals\n",
        "RES_PATH = \"C://Users//ariji//Desktop//ai_trace//models//official_wiki_residuals.pkl\"\n",
        "with open(RES_PATH, \"rb\") as f:\n",
        "    residuals_dict = pickle.load(f)\n",
        "\n",
        "def extract_enhanced_features(residual):\n",
        "    \"\"\"Extract comprehensive features: PRNU correlation + FFT + LBP + Texture\"\"\"\n",
        "\n",
        "    # 1. FFT Features (frequency domain)\n",
        "    fft_img = np.abs(fft2(residual))\n",
        "    fft_img = fftshift(fft_img)\n",
        "\n",
        "    # Extract frequency bands\n",
        "    h, w = fft_img.shape\n",
        "    center_h, center_w = h//2, w//2\n",
        "\n",
        "    # Low, mid, high frequency energy\n",
        "    low_freq = np.mean(fft_img[center_h-20:center_h+20, center_w-20:center_w+20])\n",
        "    mid_freq = np.mean(fft_img[center_h-60:center_h+60, center_w-60:center_w+60]) - low_freq\n",
        "    high_freq = np.mean(fft_img) - low_freq - mid_freq\n",
        "\n",
        "    # 2. LBP Texture Features\n",
        "    lbp = local_binary_pattern(residual, P=24, R=3, method='uniform')\n",
        "    lbp_hist, _ = np.histogram(lbp, bins=26, range=(0, 25), density=True)\n",
        "\n",
        "    # 3. Statistical Texture Features\n",
        "    grad_x = ndimage.sobel(residual, axis=1)\n",
        "    grad_y = ndimage.sobel(residual, axis=0)\n",
        "    gradient_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
        "\n",
        "    texture_features = [\n",
        "        np.std(residual),           # Standard deviation\n",
        "        np.mean(np.abs(residual)),  # Mean absolute value\n",
        "        np.std(gradient_mag),       # Gradient variation\n",
        "        np.mean(gradient_mag),      # Edge strength\n",
        "    ]\n",
        "\n",
        "    return [low_freq, mid_freq, high_freq] + lbp_hist.tolist() + texture_features\n",
        "\n",
        "# Extract enhanced features for all images\n",
        "print(\"ðŸ”„ Extracting enhanced features (FFT + LBP + Texture)...\")\n",
        "enhanced_features, enhanced_labels = [], []\n",
        "\n",
        "for dataset_name in [\"Official\", \"Wikipedia\"]:\n",
        "    print(f\"Processing {dataset_name}...\")\n",
        "    for scanner, dpi_dict in tqdm(residuals_dict[dataset_name].items()):\n",
        "        for dpi, res_list in dpi_dict.items():\n",
        "            for res in res_list:\n",
        "                feat = extract_enhanced_features(res)\n",
        "                enhanced_features.append(feat)\n",
        "                enhanced_labels.append(scanner)\n",
        "\n",
        "# Save enhanced features\n",
        "ENHANCED_OUT = \"C://Users//ariji//Desktop//ai_trace//models//enhanced_features.pkl\"\n",
        "with open(ENHANCED_OUT, \"wb\") as f:\n",
        "    pickle.dump({\"features\": enhanced_features, \"labels\": enhanced_labels}, f)\n",
        "\n",
        "print(f\"âœ… Enhanced features shape: {len(enhanced_features)} x {len(enhanced_features[0])}\")\n",
        "print(f\"âœ… Saved to {ENHANCED_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhTlKcOgPyzV"
      },
      "source": [
        "                                                                  Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbt9t0_chOSH"
      },
      "source": [
        "Training using Hybrid CNN and Extracted Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (2.20.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.3.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (6.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.5)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.20.0)\n",
            "Requirement already satisfied: keras>=3.10.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.11.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.2.6)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
            "Requirement already satisfied: namex in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: pillow in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ariji\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zhk_KsCOsMrs",
        "outputId": "f5fad43b-13a7-44aa-ca3d-15c508b220b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ GPU not found, using CPU\n",
            "Hybrid train: (1894, 256, 256, 1) (1894, 27) (1894, 11)\n",
            "Hybrid test : (474, 256, 256, 1) (474, 27) (474, 11)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"scanner_hybrid\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"scanner_hybrid\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ residual            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ hp_filter (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> â”‚ residual[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚ hp_filter[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ handcrafted         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> â”‚ handcrafted[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,827</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ residual            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m1\u001b[0m)                â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ hp_filter (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚          \u001b[38;5;34m9\u001b[0m â”‚ residual[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m1\u001b[0m)                â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚        \u001b[38;5;34m320\u001b[0m â”‚ hp_filter[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu (\u001b[38;5;33mReLU\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  â”‚      \u001b[38;5;34m9,248\u001b[0m â”‚ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚     \u001b[38;5;34m18,496\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_1[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚     \u001b[38;5;34m73,856\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_2[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ handcrafted         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚    \u001b[38;5;34m295,168\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m1,792\u001b[0m â”‚ handcrafted[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m82,176\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        â”‚      \u001b[38;5;34m2,827\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">670,580</span> (2.56 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m670,580\u001b[0m (2.56 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">669,483</span> (2.55 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m669,483\u001b[0m (2.55 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,097</span> (4.29 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,097\u001b[0m (4.29 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 5s/step - accuracy: 0.2925 - loss: 1.9563 - val_accuracy: 0.1962 - val_loss: 2.3901 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 5s/step - accuracy: 0.3791 - loss: 1.5691 - val_accuracy: 0.3291 - val_loss: 1.6227 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 13s/step - accuracy: 0.4087 - loss: 1.4483 - val_accuracy: 0.2532 - val_loss: 1.9463 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 10s/step - accuracy: 0.4393 - loss: 1.3816 - val_accuracy: 0.3270 - val_loss: 2.3823 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m543s\u001b[0m 9s/step - accuracy: 0.4588 - loss: 1.3139 - val_accuracy: 0.3608 - val_loss: 1.7745 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 9s/step - accuracy: 0.4688 - loss: 1.2836 - val_accuracy: 0.3734 - val_loss: 1.7783 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 6s/step - accuracy: 0.4921 - loss: 1.2468 - val_accuracy: 0.3671 - val_loss: 2.0391 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 7s/step - accuracy: 0.5016 - loss: 1.1930 - val_accuracy: 0.3523 - val_loss: 2.1863 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 9s/step - accuracy: 0.5132 - loss: 1.1637 - val_accuracy: 0.3544 - val_loss: 3.7733 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 5s/step - accuracy: 0.5238 - loss: 1.1220 - val_accuracy: 0.3797 - val_loss: 1.9772 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 10s/step - accuracy: 0.5312 - loss: 1.0842 - val_accuracy: 0.2658 - val_loss: 3.1606 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 5s/step - accuracy: 0.5576 - loss: 1.0236 - val_accuracy: 0.4473 - val_loss: 1.4870 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 7s/step - accuracy: 0.5924 - loss: 0.9360 - val_accuracy: 0.3882 - val_loss: 2.5042 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 8s/step - accuracy: 0.6320 - loss: 0.7900 - val_accuracy: 0.2447 - val_loss: 7.1227 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1173s\u001b[0m 20s/step - accuracy: 0.6389 - loss: 0.7251 - val_accuracy: 0.3797 - val_loss: 2.3526 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 4s/step - accuracy: 0.6605 - loss: 0.6540 - val_accuracy: 0.3861 - val_loss: 3.2199 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 4s/step - accuracy: 0.6457 - loss: 0.6617 - val_accuracy: 0.6561 - val_loss: 0.7119 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 5s/step - accuracy: 0.6779 - loss: 0.6325 - val_accuracy: 0.6350 - val_loss: 0.6990 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 6s/step - accuracy: 0.6848 - loss: 0.5934 - val_accuracy: 0.6814 - val_loss: 0.6198 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 3s/step - accuracy: 0.6700 - loss: 0.5975 - val_accuracy: 0.6371 - val_loss: 0.6911 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.6811 - loss: 0.5904 - val_accuracy: 0.6540 - val_loss: 0.6367 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 3s/step - accuracy: 0.6996 - loss: 0.5737 - val_accuracy: 0.6350 - val_loss: 0.7288 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.7070 - loss: 0.5612 - val_accuracy: 0.6624 - val_loss: 0.6284 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3s/step - accuracy: 0.6959 - loss: 0.5559 - val_accuracy: 0.5738 - val_loss: 1.0033 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3s/step - accuracy: 0.7138 - loss: 0.5391 - val_accuracy: 0.6751 - val_loss: 0.6211 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - accuracy: 0.7138 - loss: 0.5260 - val_accuracy: 0.6835 - val_loss: 0.6330 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 5s/step - accuracy: 0.7186 - loss: 0.5203 - val_accuracy: 0.6962 - val_loss: 0.6092 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 4s/step - accuracy: 0.7080 - loss: 0.5513 - val_accuracy: 0.6835 - val_loss: 0.6286 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 5s/step - accuracy: 0.7218 - loss: 0.5144 - val_accuracy: 0.6920 - val_loss: 0.6220 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 6s/step - accuracy: 0.7350 - loss: 0.5276 - val_accuracy: 0.6878 - val_loss: 0.5850 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 4s/step - accuracy: 0.7281 - loss: 0.5107 - val_accuracy: 0.6667 - val_loss: 0.6213 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.7228 - loss: 0.5166 - val_accuracy: 0.7004 - val_loss: 0.5695 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - accuracy: 0.7328 - loss: 0.5090 - val_accuracy: 0.7046 - val_loss: 0.5999 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 6s/step - accuracy: 0.7281 - loss: 0.5055 - val_accuracy: 0.6793 - val_loss: 0.5930 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 4s/step - accuracy: 0.7381 - loss: 0.4887 - val_accuracy: 0.6477 - val_loss: 0.7628 - learning_rate: 5.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 4s/step - accuracy: 0.7386 - loss: 0.4940 - val_accuracy: 0.7173 - val_loss: 0.5704 - learning_rate: 5.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.7365 - loss: 0.4884 - val_accuracy: 0.7300 - val_loss: 0.5775 - learning_rate: 5.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 4s/step - accuracy: 0.7328 - loss: 0.4868 - val_accuracy: 0.6371 - val_loss: 0.7511 - learning_rate: 5.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.7386 - loss: 0.4961 - val_accuracy: 0.7152 - val_loss: 0.5577 - learning_rate: 5.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 4s/step - accuracy: 0.7587 - loss: 0.4810 - val_accuracy: 0.6582 - val_loss: 0.8030 - learning_rate: 5.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 5s/step - accuracy: 0.7455 - loss: 0.4737 - val_accuracy: 0.7089 - val_loss: 0.5935 - learning_rate: 5.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1292s\u001b[0m 22s/step - accuracy: 0.7603 - loss: 0.4622 - val_accuracy: 0.7004 - val_loss: 0.6175 - learning_rate: 5.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - accuracy: 0.7592 - loss: 0.4535 - val_accuracy: 0.6835 - val_loss: 0.6404 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.7656 - loss: 0.4434 - val_accuracy: 0.6540 - val_loss: 0.6405 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - accuracy: 0.7746 - loss: 0.4452 - val_accuracy: 0.7215 - val_loss: 0.5424 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 3s/step - accuracy: 0.7598 - loss: 0.4519 - val_accuracy: 0.6793 - val_loss: 0.7272 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m60/60\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 3s/step - accuracy: 0.7672 - loss: 0.4260 - val_accuracy: 0.7194 - val_loss: 0.6035 - learning_rate: 2.5000e-04\n",
            "âœ… Training complete\n",
            "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 832ms/step\n",
            "\n",
            "âœ… Test Accuracy: 73.00%\n",
            "\n",
            "âœ… Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Canon120-1       0.65      0.51      0.57        43\n",
            "  Canon120-2       0.62      0.56      0.59        43\n",
            "    Canon220       0.67      0.86      0.76        43\n",
            " Canon9000-1       0.57      0.60      0.58        43\n",
            " Canon9000-2       0.56      0.52      0.54        42\n",
            " EpsonV370-1       0.93      0.95      0.94        43\n",
            " EpsonV370-2       0.95      0.93      0.94        44\n",
            "  EpsonV39-1       0.53      0.72      0.61        43\n",
            "  EpsonV39-2       0.57      0.39      0.46        44\n",
            "   EpsonV550       1.00      0.98      0.99        43\n",
            "          HP       0.98      1.00      0.99        43\n",
            "\n",
            "    accuracy                           0.73       474\n",
            "   macro avg       0.73      0.73      0.72       474\n",
            "weighted avg       0.73      0.73      0.73       474\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ==============================\n",
        "# Hybrid CNN (Residual Image + Handcrafted Features) with GPU\n",
        "# ==============================\n",
        "\n",
        "# ---- Imports & Paths ----\n",
        "import os, pickle, random, numpy as np, tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from skimage.feature import local_binary_pattern as sk_lbp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "RES_PATH = \"C://Users//ariji//Desktop//ai_trace//models//official_wiki_residuals.pkl\"\n",
        "FP_PATH = \"C://Users//ariji//Desktop//ai_trace//models//scanner_fingerprints.pkl\"\n",
        "ORDER_NPY = \"C://Users//ariji//Desktop//ai_trace//models//fp_keys.npy\"\n",
        "ART_DIR   = \"C://Users//ariji//Desktop//ai_trace//processed_data\"\n",
        "os.makedirs(ART_DIR, exist_ok=True)\n",
        "\n",
        "# ---- Reproducibility ----\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ---- GPU Setup ----\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    device_name = '/GPU:0'\n",
        "    print(\"âœ… Using GPU:\", gpus[0])\n",
        "else:\n",
        "    device_name = '/CPU:0'\n",
        "    print(\"âš ï¸ GPU not found, using CPU\")\n",
        "\n",
        "# ---- Load residuals + fingerprints ----\n",
        "with open(RES_PATH, \"rb\") as f:\n",
        "    residuals_dict = pickle.load(f)\n",
        "with open(FP_PATH, \"rb\") as f:\n",
        "    scanner_fps = pickle.load(f)\n",
        "fp_keys = np.load(ORDER_NPY, allow_pickle=True).tolist()\n",
        "\n",
        "# ---- Utilities ----\n",
        "def corr2d(a, b):\n",
        "    a = a.astype(np.float32).ravel(); b = b.astype(np.float32).ravel()\n",
        "    a -= a.mean(); b -= b.mean()\n",
        "    d = np.linalg.norm(a)*np.linalg.norm(b)\n",
        "    return float((a @ b) / d) if d != 0 else 0.0\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img))\n",
        "    mag = np.abs(f)\n",
        "    h, w = mag.shape; cy, cx = h//2, w//2\n",
        "    yy, xx = np.ogrid[:h, :w]\n",
        "    r = np.sqrt((yy - cy)**2 + (xx - cx)**2)\n",
        "    rmax = r.max() + 1e-6\n",
        "    bins = np.linspace(0, rmax, K+1)\n",
        "    feats = []\n",
        "    for i in range(K):\n",
        "        m = (r >= bins[i]) & (r < bins[i+1])\n",
        "        feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return feats\n",
        "\n",
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng = float(np.ptp(img))\n",
        "    if rng < 1e-12:\n",
        "        g = np.zeros_like(img, dtype=np.float32)\n",
        "    else:\n",
        "        g = (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8 = (g * 255.0).astype(np.uint8)\n",
        "    codes = sk_lbp(g8, P=P, R=R, method=\"uniform\")\n",
        "    n_bins = P + 2\n",
        "    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "    return hist.astype(np.float32).tolist()\n",
        "\n",
        "# ---- Build dataset ----\n",
        "X_img, X_feat, y = [], [], []\n",
        "for dataset_name in [\"Official\", \"Wikipedia\"]:\n",
        "    for scanner, dpi_dict in residuals_dict[dataset_name].items():\n",
        "        for dpi, res_list in dpi_dict.items():\n",
        "            for res in res_list:\n",
        "                X_img.append(np.expand_dims(res, axis=-1))\n",
        "                v_corr = [corr2d(res, scanner_fps[k]) for k in fp_keys]\n",
        "                v_fft  = fft_radial_energy(res, K=6)\n",
        "                v_lbp  = lbp_hist_safe(res, P=8, R=1.0)\n",
        "                X_feat.append(v_corr + v_fft + v_lbp)\n",
        "                y.append(scanner)\n",
        "\n",
        "X_img  = np.array(X_img, dtype=np.float32)\n",
        "X_feat = np.array(X_feat, dtype=np.float32)\n",
        "y       = np.array(y)\n",
        "\n",
        "# ---- Encode labels ----\n",
        "le = LabelEncoder()\n",
        "y_int = le.fit_transform(y)\n",
        "num_classes = len(le.classes_)\n",
        "y_cat = to_categorical(y_int, num_classes)\n",
        "\n",
        "X_img_tr, X_img_te, X_feat_tr, X_feat_te, y_tr, y_te = train_test_split(\n",
        "    X_img, X_feat, y_cat, test_size=0.2, random_state=SEED, stratify=y_int\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_feat_tr = scaler.fit_transform(X_feat_tr)\n",
        "X_feat_te = scaler.transform(X_feat_te)\n",
        "\n",
        "with open(os.path.join(ART_DIR, \"hybrid_label_encoder.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(le, f)\n",
        "with open(os.path.join(ART_DIR, \"hybrid_feat_scaler.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print(\"Hybrid train:\", X_img_tr.shape, X_feat_tr.shape, y_tr.shape)\n",
        "print(\"Hybrid test :\", X_img_te.shape, X_feat_te.shape, y_te.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# Build, Train & Evaluate with GPU\n",
        "# -------------------------------\n",
        "with tf.device(device_name):\n",
        "    # ---- Model ----\n",
        "    img_in  = keras.Input(shape=(256,256,1), name=\"residual\")\n",
        "    feat_in = keras.Input(shape=(27,),      name=\"handcrafted\")\n",
        "    hp_kernel = np.array([[-1,-1,-1], [-1,8,-1], [-1,-1,-1]], dtype=np.float32).reshape((3,3,1,1))\n",
        "    hp = layers.Conv2D(1, (3,3), padding=\"same\", use_bias=False, trainable=False, name=\"hp_filter\")(img_in)\n",
        "\n",
        "    # CNN branch\n",
        "    x = layers.Conv2D(32,(3,3),padding=\"same\")(hp)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(32,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x); x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Conv2D(64,(3,3),padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(64,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x); x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Conv2D(128,(3,3),padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.Conv2D(128,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x); x = layers.Dropout(0.30)(x)\n",
        "\n",
        "    x = layers.Conv2D(256,(3,3),padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Feature branch\n",
        "    f = layers.Dense(64)(feat_in)\n",
        "    f = layers.BatchNormalization()(f); f = layers.ReLU()(f)\n",
        "    f = layers.Dropout(0.20)(f)\n",
        "\n",
        "    # Fusion\n",
        "    z = layers.Concatenate()([x,f])\n",
        "    z = layers.Dense(256, activation=\"relu\")(z)\n",
        "    z = layers.Dropout(0.40)(z)\n",
        "    out = layers.Dense(num_classes, activation=\"softmax\")(z)\n",
        "\n",
        "    model = keras.Model(inputs=[img_in, feat_in], outputs=out, name=\"scanner_hybrid\")\n",
        "    model.get_layer(\"hp_filter\").set_weights([hp_kernel])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                  loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "\n",
        "    # ---- tf.data pipelines ----\n",
        "    BATCH = 32\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(((X_img_tr, X_feat_tr), y_tr))\\\n",
        "        .shuffle(len(y_tr), reshuffle_each_iteration=True)\\\n",
        "        .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "    val_ds   = tf.data.Dataset.from_tensor_slices(((X_img_te, X_feat_te), y_te))\\\n",
        "        .batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    # ---- Callbacks ----\n",
        "    ckpt_path = os.path.join(ART_DIR, \"scanner_hybrid.keras\")\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_accuracy\"),\n",
        "        keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6, monitor=\"val_accuracy\"),\n",
        "        keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\"),\n",
        "    ]\n",
        "\n",
        "    # ---- Train ----\n",
        "    EPOCHS = 50\n",
        "    history = model.fit(train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=callbacks, verbose=1)\n",
        "\n",
        "    # ---- Save model & history ----\n",
        "    model.save(os.path.join(ART_DIR, \"scanner_hybrid_final.keras\"))\n",
        "    with open(os.path.join(ART_DIR, \"hybrid_training_history.pkl\"), \"wb\") as f:\n",
        "        pickle.dump(history.history, f)\n",
        "    print(\"âœ… Training complete\")\n",
        "\n",
        "    # ---- Evaluate ----\n",
        "    y_pred_prob = model.predict(val_ds)\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "    y_true = np.argmax(y_te, axis=1)\n",
        "\n",
        "\n",
        "    test_acc = accuracy_score(y_true, y_pred)\n",
        "    print(f\"\\nâœ… Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "    print(\"\\nâœ… Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agmnx6UsQmg-",
        "outputId": "5b7ea4c0-cb10-4c44-c133-a7b09bde48d4"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3444144118.py, line 3)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mgpus = tf.config.list_physical_devices('GPU')vq\u001b[39m\n                                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')vq\n",
        "print(\"GPUs detected:\", gpus)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED0JFl1ijCj2"
      },
      "source": [
        "                                                                   Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tD_bFj2l2l0",
        "outputId": "096df110-4345-4b58-c687-4d7c7a3fb742"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Cannot read C:\\Users\\ariji\\Desktop\\ai_trace\\process_data\\Wikipedia",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    109\u001b[39m test_paths = [\n\u001b[32m    110\u001b[39m    \u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mariji\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mai_trace\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mprocess_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mWikipedia\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m ]\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m test_paths:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     label, conf = \u001b[43mpredict_scanner_hybrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconf\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mpredict_scanner_hybrid\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_scanner_hybrid\u001b[39m(image_path):\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     res   = \u001b[43mpreprocess_residual_pywt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     x_img = np.expand_dims(res, axis=(\u001b[32m0\u001b[39m,-\u001b[32m1\u001b[39m))  \u001b[38;5;66;03m# (1,256,256,1)\u001b[39;00m\n\u001b[32m     99\u001b[39m     x_ft  = make_feats_from_res(res)          \u001b[38;5;66;03m# (1,27)\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mpreprocess_residual_pywt\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     73\u001b[39m img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot read \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m img.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m     77\u001b[39m     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
            "\u001b[31mValueError\u001b[39m: Cannot read C:\\Users\\ariji\\Desktop\\ai_trace\\process_data\\Wikipedia"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pywt\n",
        "import cv2\n",
        "\n",
        "# -----------------------\n",
        "# Paths\n",
        "# -----------------------\n",
        "ART_DIR = \"C://Users//ariji//Desktop//ai_trace//models\"\n",
        "FP_PATH = os.path.join(ART_DIR, \"scanner_fingerprints.pkl\")\n",
        "ORDER_NPY = os.path.join(ART_DIR, \"fp_keys.npy\")\n",
        "ckpt_path = os.path.join(ART_DIR, \"scanner_hybrid.keras\")  # <-- checkpoint path\n",
        "\n",
        "# -----------------------\n",
        "# Reload for inference\n",
        "# -----------------------\n",
        "hyb_model = tf.keras.models.load_model(ckpt_path, compile=False)\n",
        "\n",
        "with open(os.path.join(ART_DIR, \"hybrid_label_encoder.pkl\"), \"rb\") as f:\n",
        "    le_inf = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(ART_DIR, \"hybrid_feat_scaler.pkl\"), \"rb\") as f:\n",
        "    scaler_inf = pickle.load(f)\n",
        "\n",
        "with open(FP_PATH, \"rb\") as f:\n",
        "    scanner_fps_inf = pickle.load(f)\n",
        "\n",
        "fp_keys_inf = np.load(ORDER_NPY, allow_pickle=True).tolist()\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "# -----------------------\n",
        "# Utility functions\n",
        "# -----------------------\n",
        "def corr2d(a, b):\n",
        "    a = a.astype(np.float32).ravel(); b = b.astype(np.float32).ravel()\n",
        "    a -= a.mean(); b -= b.mean()\n",
        "    d = np.linalg.norm(a) * np.linalg.norm(b)\n",
        "    return float((a @ b) / d) if d != 0 else 0.0\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img))\n",
        "    mag = np.abs(f)\n",
        "    h, w = mag.shape; cy, cx = h//2, w//2\n",
        "    yy, xx = np.ogrid[:h, :w]\n",
        "    r = np.sqrt((yy - cy)**2 + (xx - cx)**2)\n",
        "    rmax = r.max() + 1e-6\n",
        "    bins = np.linspace(0, rmax, K+1)\n",
        "    feats = []\n",
        "    for i in range(K):\n",
        "        m = (r >= bins[i]) & (r < bins[i+1])\n",
        "        feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return feats\n",
        "\n",
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng = float(np.ptp(img))\n",
        "    if rng < 1e-12:\n",
        "        g = np.zeros_like(img, dtype=np.float32)\n",
        "    else:\n",
        "        g = (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8 = (g * 255.0).astype(np.uint8)\n",
        "    from skimage.feature import local_binary_pattern\n",
        "    codes = local_binary_pattern(g8, P=P, R=R, method=\"uniform\")\n",
        "    n_bins = P + 2\n",
        "    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "    return hist.astype(np.float32).tolist()\n",
        "\n",
        "# -----------------------\n",
        "# Preprocess + Features\n",
        "# -----------------------\n",
        "def preprocess_residual_pywt(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Cannot read {path}\")\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    cA, (cH, cV, cD) = pywt.dwt2(img, 'haar')\n",
        "    cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "    den = pywt.idwt2((cA, (cH, cV, cD)), 'haar')\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "def make_feats_from_res(res):\n",
        "    v_corr = [corr2d(res, scanner_fps_inf[k]) for k in fp_keys_inf]\n",
        "    v_fft  = fft_radial_energy(res, K=6)\n",
        "    v_lbp  = lbp_hist_safe(res, P=8, R=1.0)\n",
        "    v = np.array(v_corr + v_fft + v_lbp, dtype=np.float32).reshape(1,-1)\n",
        "    v = scaler_inf.transform(v)\n",
        "    return v\n",
        "\n",
        "# -----------------------\n",
        "# Prediction function\n",
        "# -----------------------\n",
        "def predict_scanner_hybrid(image_path):\n",
        "    res   = preprocess_residual_pywt(image_path)\n",
        "    x_img = np.expand_dims(res, axis=(0,-1))  # (1,256,256,1)\n",
        "    x_ft  = make_feats_from_res(res)          # (1,27)\n",
        "    prob  = hyb_model.predict([x_img, x_ft], verbose=0)\n",
        "    idx   = int(np.argmax(prob))\n",
        "    label = le_inf.classes_[idx]\n",
        "    conf  = float(prob[0, idx]*100.0)\n",
        "    return label, conf\n",
        "\n",
        "# -----------------------\n",
        "# Multiple image prediction\n",
        "# -----------------------\n",
        "test_paths = [\n",
        "   \"C://Users//ariji//Desktop//ai_trace//process_data//Official//Canon220 (1)//150//s3_4.tif\",\n",
        "   \"C://Users//ariji//Desktop//ai_trace//process_data//Official//EpsonV39-1 (1)//300//s8_4.tif\",\n",
        "   \"C://Users//ariji//Desktop//ai_trace//process_data//Wikipedia//Canon220//150//s3_3.tif\",\n",
        "]\n",
        "\n",
        "for p in test_paths:\n",
        "    label, conf = predict_scanner_hybrid(p)\n",
        "    print(f\"{p} -> {label} | Confidence: {conf:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nwavoPuBXSt",
        "outputId": "b5cf008d-c4e2-4720-89f0-acf9f011e4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 images in /content/drive/MyDrive/AI_TRACEFINDER_DS/Test\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Test/s10_106.tif -> EpsonV550 | Confidence: 98.94%\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Test/s5_105.tif -> Canon9000-2 | Confidence: 97.52%\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Test/s11_107.tif -> HP | Confidence: 100.00%\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Test/s11_104.tif -> HP | Confidence: 100.00%\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Test/s8_108.tif -> EpsonV39-1 | Confidence: 76.29%\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Test/s8_102.tif -> EpsonV39-1 | Confidence: 68.96%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pywt\n",
        "import cv2\n",
        "\n",
        "# -----------------------\n",
        "# Paths\n",
        "# -----------------------\n",
        "ART_DIR = \"/content/drive/MyDrive/AI_TRACEFINDER_DS\"\n",
        "FP_PATH = os.path.join(ART_DIR, \"scanner_fingerprints.pkl\")\n",
        "ORDER_NPY = os.path.join(ART_DIR, \"fp_keys.npy\")\n",
        "ckpt_path = os.path.join(ART_DIR, \"scanner_hybrid.keras\")  # checkpoint path\n",
        "\n",
        "# -----------------------\n",
        "# Reload for inference\n",
        "# -----------------------\n",
        "hyb_model = tf.keras.models.load_model(ckpt_path, compile=False)\n",
        "\n",
        "with open(os.path.join(ART_DIR, \"hybrid_label_encoder.pkl\"), \"rb\") as f:\n",
        "    le_inf = pickle.load(f)\n",
        "\n",
        "with open(os.path.join(ART_DIR, \"hybrid_feat_scaler.pkl\"), \"rb\") as f:\n",
        "    scaler_inf = pickle.load(f)\n",
        "\n",
        "with open(FP_PATH, \"rb\") as f:\n",
        "    scanner_fps_inf = pickle.load(f)\n",
        "\n",
        "fp_keys_inf = np.load(ORDER_NPY, allow_pickle=True).tolist()\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "# -----------------------\n",
        "# Utility functions\n",
        "# -----------------------\n",
        "def corr2d(a, b):\n",
        "    a = a.astype(np.float32).ravel(); b = b.astype(np.float32).ravel()\n",
        "    a -= a.mean(); b -= b.mean()\n",
        "    d = np.linalg.norm(a) * np.linalg.norm(b)\n",
        "    return float((a @ b) / d) if d != 0 else 0.0\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img))\n",
        "    mag = np.abs(f)\n",
        "    h, w = mag.shape; cy, cx = h//2, w//2\n",
        "    yy, xx = np.ogrid[:h, :w]\n",
        "    r = np.sqrt((yy - cy)**2 + (xx - cx)**2)\n",
        "    rmax = r.max() + 1e-6\n",
        "    bins = np.linspace(0, rmax, K+1)\n",
        "    feats = []\n",
        "    for i in range(K):\n",
        "        m = (r >= bins[i]) & (r < bins[i+1])\n",
        "        feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return feats\n",
        "\n",
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng = float(np.ptp(img))\n",
        "    if rng < 1e-12:\n",
        "        g = np.zeros_like(img, dtype=np.float32)\n",
        "    else:\n",
        "        g = (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8 = (g * 255.0).astype(np.uint8)\n",
        "    from skimage.feature import local_binary_pattern\n",
        "    codes = local_binary_pattern(g8, P=P, R=R, method=\"uniform\")\n",
        "    n_bins = P + 2\n",
        "    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "    return hist.astype(np.float32).tolist()\n",
        "\n",
        "# -----------------------\n",
        "# Preprocess + Features\n",
        "# -----------------------\n",
        "def preprocess_residual_pywt(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Cannot read {path}\")\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    cA, (cH, cV, cD) = pywt.dwt2(img, 'haar')\n",
        "    cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "    den = pywt.idwt2((cA, (cH, cV, cD)), 'haar')\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "def make_feats_from_res(res):\n",
        "    v_corr = [corr2d(res, scanner_fps_inf[k]) for k in fp_keys_inf]\n",
        "    v_fft  = fft_radial_energy(res, K=6)\n",
        "    v_lbp  = lbp_hist_safe(res, P=8, R=1.0)\n",
        "    v = np.array(v_corr + v_fft + v_lbp, dtype=np.float32).reshape(1,-1)\n",
        "    v = scaler_inf.transform(v)\n",
        "    return v\n",
        "\n",
        "# -----------------------\n",
        "# Prediction function\n",
        "# -----------------------\n",
        "def predict_scanner_hybrid(image_path):\n",
        "    res   = preprocess_residual_pywt(image_path)\n",
        "    x_img = np.expand_dims(res, axis=(0,-1))  # (1,256,256,1)\n",
        "    x_ft  = make_feats_from_res(res)          # (1,27)\n",
        "    prob  = hyb_model.predict([x_img, x_ft], verbose=0)\n",
        "    idx   = int(np.argmax(prob))\n",
        "    label = le_inf.classes_[idx]\n",
        "    conf  = float(prob[0, idx]*100.0)\n",
        "    return label, conf\n",
        "\n",
        "# -----------------------\n",
        "# Predict all images in a folder\n",
        "# -----------------------\n",
        "def predict_folder(folder_path, exts=(\"*.tif\",\"*.png\",\"*.jpg\",\"*.jpeg\")):\n",
        "    # Gather all files recursively\n",
        "    image_files = []\n",
        "    for ext in exts:\n",
        "        image_files.extend(glob.glob(os.path.join(folder_path, \"**\", ext), recursive=True))\n",
        "    print(f\"Found {len(image_files)} images in {folder_path}\")\n",
        "\n",
        "    # Predict each\n",
        "    results = []\n",
        "    for img_path in image_files:\n",
        "        try:\n",
        "            label, conf = predict_scanner_hybrid(img_path)\n",
        "            results.append((img_path, label, conf))\n",
        "            print(f\"{img_path} -> {label} | Confidence: {conf:.2f}%\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error processing {img_path}: {e}\")\n",
        "    return results\n",
        "\n",
        "# -----------------------\n",
        "# Example usage\n",
        "# -----------------------\n",
        "folder_to_test = \"/content/drive/MyDrive/AI_TRACEFINDER_DS/Test\"\n",
        "all_results = predict_folder(folder_to_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp-cyxWQ7Ajf"
      },
      "source": [
        "                                                              Tampered detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8x4XxO6m7Ajg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "ROOT = \"/content/drive/MyDrive/AI_TRACEFINDER_DS\"\n",
        "\n",
        "# Originals PDFs to convert â†’ TIFF\n",
        "ORIG_PDF_OFF = f\"{ROOT}/Originals/official\"\n",
        "ORIG_PDF_WIK = f\"{ROOT}/Originals/wikipedia\"\n",
        "CONV_OUT     = f\"{ROOT}/Originals_tif\"           # output for converted TIFFs\n",
        "os.makedirs(CONV_OUT, exist_ok=True)\n",
        "\n",
        "# Tampered images TIFFs\n",
        "TAMP_ROOT     = f\"{ROOT}/TamperedImages\"\n",
        "TAMP_ORIG_TIF = f\"{TAMP_ROOT}/Original\"                          # clean (0)\n",
        "TAMP_COPY_TIF = f\"{TAMP_ROOT}/Tampered/Copy-move\"                # tampered (1)\n",
        "TAMP_RETO_TIF = f\"{TAMP_ROOT}/Tampered/Retouching\"               # tampered (1)\n",
        "TAMP_SPLI_TIF = f\"{TAMP_ROOT}/Tampered/Splicing\"                 # tampered (1)\n",
        "\n",
        "# Artifacts / manifests\n",
        "ART_DIR      = f\"{ROOT}/artifacts_tamper\"\n",
        "MANIFEST_CSV = f\"{ROOT}/manifests/tamper_manifest.csv\"\n",
        "os.makedirs(ART_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(MANIFEST_CSV), exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "960uLpteQ0Gj",
        "outputId": "d2f1b573-045f-48ba-8171-c4e7c76cb023"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv2EkSiJQ9tL",
        "outputId": "7b023762-08af-489f-99e8-90480931b0b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PDFâ†’TIFF 300dpi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208/208 [03:32<00:00,  1.02s/it]\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "from pathlib import Path\n",
        "from PIL import Image  # Pillow (PIL) [web:28]\n",
        "\n",
        "import pymupdf as fitz  # modern namespace; keeps existing fitz.* calls working [web:14][web:30]\n",
        "\n",
        "def pdf_to_tiffs(pdf_path, out_dir, dpi=300):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for i, page in enumerate(doc):\n",
        "        pix = page.get_pixmap(dpi=dpi)  # documented DPI rendering\n",
        "        mode = \"RGB\" if pix.alpha == 0 else \"RGBA\"\n",
        "        img = Image.frombytes(mode, [pix.width, pix.height], pix.samples)\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "        stem = Path(pdf_path).stem\n",
        "        outp = f\"{out_dir}/{stem}_p{i+1}.tif\"\n",
        "        img.save(outp, format=\"TIFF\", dpi=(dpi, dpi), compression=\"tiff_deflate\")\n",
        "    doc.close()\n",
        "\n",
        "def batch_convert_originals():\n",
        "    tasks = []\n",
        "    for sub in [\"official\", \"wikipedia\"]:\n",
        "        src_root = f\"{ROOT}/Originals/{sub}\"\n",
        "        dst_root = f\"{CONV_OUT}/{sub}\"\n",
        "        os.makedirs(dst_root, exist_ok=True)\n",
        "        for pdf in glob.glob(f\"{src_root}/**/*.pdf\", recursive=True):\n",
        "            parent = Path(pdf).parent.name\n",
        "            out_dir = f\"{dst_root}/{parent}\"\n",
        "            tasks.append((pdf, out_dir))\n",
        "    for pdf, outd in tqdm(tasks, desc=\"PDFâ†’TIFF 300dpi\"):\n",
        "        try:\n",
        "            pdf_to_tiffs(pdf, outd, dpi=300)\n",
        "        except Exception as e:\n",
        "            print(\"Failed:\", pdf, \"->\", e)\n",
        "\n",
        "batch_convert_originals()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "C6VJ2i6jVccG"
      },
      "outputs": [],
      "source": [
        "ROOT = \"/content/drive/MyDrive/AI_TRACEFINDER_DS\"\n",
        "ORIG_TIF_OFF = f\"{ROOT}/Originals_tif/official\"\n",
        "ORIG_TIF_WIK = f\"{ROOT}/Originals_tif/wikipedia\"\n",
        "TAMP_ROOT    = f\"{ROOT}/TamperedImages\"\n",
        "TAMP_ORIG_TF = f\"{TAMP_ROOT}/Original\"\n",
        "TAMP_CM_TF   = f\"{TAMP_ROOT}/Tampered/Copy-move\"\n",
        "TAMP_RT_TF   = f\"{TAMP_ROOT}/Tampered/Retouching\"\n",
        "TAMP_SP_TF   = f\"{TAMP_ROOT}/Tampered/Splicing\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQNMMPjCYAiT",
        "outputId": "c5f11184-3c80-480b-866e-5e7b4fd12a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote manifest: /content/drive/MyDrive/AI_TRACEFINDER_DS/manifests/tamper_manifest_grouped.csv rows: 344\n"
          ]
        }
      ],
      "source": [
        "import os, glob, csv, re\n",
        "from pathlib import Path\n",
        "\n",
        "MANIFEST_CSV = f\"{ROOT}/manifests/tamper_manifest_grouped.csv\"\n",
        "os.makedirs(os.path.dirname(MANIFEST_CSV), exist_ok=True)\n",
        "\n",
        "def list_tifs(root):\n",
        "    return sorted([p for p in glob.glob(f\"{root}/**/*\", recursive=True)\n",
        "                   if p.lower().endswith((\".tif\",\".tiff\"))])\n",
        "\n",
        "def infer_page_id(p):\n",
        "    m = re.search(r\"(s\\d+_\\d+)\", os.path.basename(p))\n",
        "    if m: return m.group(1)\n",
        "    stem = Path(p).stem\n",
        "    stem = re.sub(r\"_p\\d+$\",\"\", stem)\n",
        "    return stem\n",
        "\n",
        "rows = [[\"path\",\"label\",\"domain\",\"tamper_type\",\"page_id\"]]\n",
        "for p in list_tifs(ORIG_TIF_OFF): rows.append([p, 0, \"orig_pdf_tif\", \"clean\",     infer_page_id(p)])\n",
        "for p in list_tifs(ORIG_TIF_WIK): rows.append([p, 0, \"orig_pdf_tif\", \"clean\",     infer_page_id(p)])\n",
        "for p in list_tifs(TAMP_ORIG_TF): rows.append([p, 0, \"tamper_dir\",   \"clean\",     infer_page_id(p)])\n",
        "for p in list_tifs(TAMP_CM_TF):   rows.append([p, 1, \"tamper_dir\",   \"copy-move\", infer_page_id(p)])\n",
        "for p in list_tifs(TAMP_RT_TF):   rows.append([p, 1, \"tamper_dir\",   \"retouch\",   infer_page_id(p)])\n",
        "for p in list_tifs(TAMP_SP_TF):   rows.append([p, 1, \"tamper_dir\",   \"splice\",    infer_page_id(p)])\n",
        "\n",
        "with open(MANIFEST_CSV, \"w\", newline=\"\") as fh:\n",
        "    csv.writer(fh).writerows(rows)\n",
        "print(\"Wrote manifest:\", MANIFEST_CSV, \"rows:\", len(rows)-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VH2GlFk-YGzV"
      },
      "outputs": [],
      "source": [
        "import numpy as np, cv2, pywt, math\n",
        "from skimage.feature import local_binary_pattern as sk_lbp\n",
        "\n",
        "IMG_SIZE = (256,256)\n",
        "PATCH = 128\n",
        "STRIDE = 64\n",
        "MAX_PATCHES = 16\n",
        "\n",
        "def load_to_residual(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None: raise ValueError(f\"Cannot read {path}\")\n",
        "    if img.ndim == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA).astype(np.float32)/255.0\n",
        "    cA,(cH,cV,cD) = pywt.dwt2(img, \"haar\")\n",
        "    cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "    den = pywt.idwt2((cA,(cH,cV,cD)), \"haar\")\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "def extract_patches(res, patch=PATCH, stride=STRIDE, limit=MAX_PATCHES, seed=42):\n",
        "    H,W = res.shape\n",
        "    ys = list(range(0, H-patch+1, stride))\n",
        "    xs = list(range(0, W-patch+1, stride))\n",
        "    coords = [(y,x) for y in ys for x in xs]\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(coords)\n",
        "    coords = coords[:min(limit, len(coords))]\n",
        "    return [res[y:y+patch, x:x+patch] for y,x in coords]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EfjT0EDMYJtm"
      },
      "outputs": [],
      "source": [
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng = float(np.ptp(img))\n",
        "    g = np.zeros_like(img, dtype=np.float32) if rng < 1e-12 else (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8 = (g * 255.0).astype(np.uint8)\n",
        "    codes = sk_lbp(g8, P=P, R=R, method=\"uniform\")\n",
        "    n_bins = P + 2\n",
        "    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "    h,w = mag.shape; cy,cx = h//2, w//2\n",
        "    yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "    bins = np.linspace(0, r.max()+1e-6, K+1)\n",
        "    feats=[]\n",
        "    for i in range(K):\n",
        "        m = (r>=bins[i]) & (r<bins[i+1]); feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return np.asarray(feats, dtype=np.float32)\n",
        "\n",
        "def residual_stats(img):\n",
        "    return np.asarray([float(img.mean()), float(img.std()), float(np.mean(np.abs(img)))], dtype=np.float32)\n",
        "\n",
        "def fft_resample_feats(img):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "    h,w = mag.shape; cy,cx = h//2, w//2\n",
        "    yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "    rmax = r.max()+1e-6\n",
        "    b1 = (r>=0.25*rmax) & (r<0.35*rmax)\n",
        "    b2 = (r>=0.35*rmax) & (r<0.50*rmax)\n",
        "    e1 = float(mag[b1].mean() if b1.any() else 0.0)\n",
        "    e2 = float(mag[b2].mean() if b2.any() else 0.0)\n",
        "    ratio = float(e2/(e1+1e-8))\n",
        "    return np.asarray([e1, e2, ratio], dtype=np.float32)\n",
        "\n",
        "def make_feat_vector(img_patch):\n",
        "    lbp = lbp_hist_safe(img_patch,8,1.0)      # 10\n",
        "    fft6 = fft_radial_energy(img_patch,6)     # 6\n",
        "    res3 = residual_stats(img_patch)          # 3\n",
        "    rsp3 = fft_resample_feats(img_patch)      # 3\n",
        "    return np.concatenate([lbp, fft6, res3, rsp3], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxva2-rvYNue",
        "outputId": "448b63e2-0da0-4187-be6a-9e9fdc37ee23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "patchify+debias: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [06:28<00:00,  2.88s/it]\n",
            "patchify+debias: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [02:14<00:00,  1.92s/it]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "with open(MANIFEST_CSV, \"r\") as fh:\n",
        "    rr = list(csv.DictReader(fh))\n",
        "\n",
        "paths  = np.array([r[\"path\"] for r in rr], dtype=object)\n",
        "labels = np.array([int(r[\"label\"]) for r in rr], dtype=np.int64)\n",
        "groups = np.array([r[\"page_id\"] for r in rr], dtype=object)\n",
        "domain = np.array([r[\"domain\"] for r in rr], dtype=object)\n",
        "ttype  = np.array([r[\"tamper_type\"] for r in rr], dtype=object)\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tr_idx, va_idx = next(sgkf.split(paths, labels, groups))\n",
        "\n",
        "def augment_patch(p):\n",
        "    a = p.copy()\n",
        "    a = a + 0.003*np.random.randn(*a.shape)\n",
        "    if np.random.rand()<0.5:\n",
        "        a = cv2.GaussianBlur(a, (3,3), 0)\n",
        "    a = np.clip(a, 0.0, 1.0).astype(np.float32)\n",
        "    return a\n",
        "\n",
        "def build_patchset(idxs, balance_clean_domains=True, seed=42, aug_clean_tdir=True):\n",
        "    Xp, yp, dp, tp, gp, ip = [], [], [], [], [], []\n",
        "    rng = np.random.RandomState(seed)\n",
        "    idxs_clean = [i for i in idxs if labels[i]==0]\n",
        "    idxs_clean_orig = [i for i in idxs_clean if domain[i]==\"orig_pdf_tif\"]\n",
        "    idxs_clean_tdir = [i for i in idxs_clean if domain[i]==\"tamper_dir\"]\n",
        "    if balance_clean_domains and len(idxs_clean_orig)>0 and len(idxs_clean_tdir)>0:\n",
        "        cap = min(len(idxs_clean_orig), len(idxs_clean_tdir))\n",
        "        rng.shuffle(idxs_clean_orig); rng.shuffle(idxs_clean_tdir)\n",
        "        idxs_use = idxs_clean_orig[:cap] + idxs_clean_tdir[:cap] + [i for i in idxs if labels[i]==1]\n",
        "    else:\n",
        "        idxs_use = list(idxs)\n",
        "    for i in tqdm(idxs_use, desc=\"patchify+debias\"):\n",
        "        res = load_to_residual(paths[i])\n",
        "        patches = extract_patches(res, limit=MAX_PATCHES, seed=(seed+i)%10000)\n",
        "        for pch in patches:\n",
        "            if aug_clean_tdir and labels[i]==0 and domain[i]==\"tamper_dir\":\n",
        "                pch = augment_patch(pch)\n",
        "            Xp.append(make_feat_vector(pch))\n",
        "            yp.append(labels[i]); dp.append(domain[i]); tp.append(ttype[i]); gp.append(groups[i]); ip.append(paths[i])\n",
        "    return np.asarray(Xp, np.float32), np.asarray(yp, np.int64), np.array(dp, dtype=object), np.array(tp, dtype=object), np.array(gp, dtype=object), np.array(ip, dtype=object)\n",
        "\n",
        "Xtr, ytr, dtr, ttr, gtr, itr = build_patchset(tr_idx, balance_clean_domains=True, aug_clean_tdir=True)\n",
        "Xva, yva, dva, tva, gva, iva = build_patchset(va_idx, balance_clean_domains=False, aug_clean_tdir=False)\n",
        "\n",
        "scaler = StandardScaler().fit(Xtr)\n",
        "Xs_tr = scaler.transform(Xtr)\n",
        "Xs_va = scaler.transform(Xva)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cKw8DO2YTYe",
        "outputId": "75a0aee9-f050-45d9-9be3-8396dd5afb6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.9958847736625515\n",
            "Validation Patch-level AUC: 0.9268977432242739\n",
            "Global thr: 0.8021084715652925\n",
            "Per-domain: {'tamper_dir': 0.9998674879604224}\n",
            "Per-type: {'copy-move': 0.8375097641011239, 'retouch': 0.8375097641011239, 'splice': 0.8021084715652925}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# --- Scale features ---\n",
        "scaler = StandardScaler().fit(Xtr)   # fit only on train\n",
        "Xs_tr = scaler.transform(Xtr)\n",
        "Xs_va = scaler.transform(Xva)\n",
        "\n",
        "# --- Train classifier ---\n",
        "base = SVC(kernel=\"rbf\", C=2.0, gamma=\"scale\", probability=False,\n",
        "           class_weight=\"balanced\", random_state=42)\n",
        "clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5).fit(Xs_tr, ytr)\n",
        "\n",
        "# --- Training accuracy ---\n",
        "train_acc = clf.score(Xs_tr, ytr)\n",
        "print(\"Training accuracy:\", train_acc)\n",
        "\n",
        "# --- Validation AUC ---\n",
        "probs_va = clf.predict_proba(Xs_va)[:, 1]\n",
        "auc_patch = roc_auc_score(yva, probs_va)\n",
        "print(\"Validation Patch-level AUC:\", auc_patch)\n",
        "\n",
        "# --- Threshold selection ---\n",
        "def best_thr(y, p):\n",
        "    fpr, tpr, thr = roc_curve(y, p)\n",
        "    j = tpr - fpr\n",
        "    return float(thr[int(np.argmax(j))])\n",
        "\n",
        "thr_global = best_thr(yva, probs_va)\n",
        "\n",
        "thr_by_domain = {}\n",
        "for dom in [\"orig_pdf_tif\", \"tamper_dir\"]:\n",
        "    m = (dva == dom)\n",
        "    if m.any() and len(np.unique(yva[m])) == 2:\n",
        "        thr_by_domain[dom] = best_thr(yva[m], probs_va[m])\n",
        "\n",
        "thr_by_type = {}\n",
        "for t in [\"copy-move\", \"retouch\", \"splice\"]:\n",
        "    m = (tva == t) | (tva == \"clean\")\n",
        "    if m.any() and len(np.unique(yva[m])) == 2:\n",
        "        thr_by_type[t] = best_thr(yva[m], probs_va[m])\n",
        "\n",
        "print(\"Global thr:\", thr_global)\n",
        "print(\"Per-domain:\", thr_by_domain)\n",
        "print(\"Per-type:\", thr_by_type)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fuMjr0SYWu9",
        "outputId": "d88029ab-162f-410d-a1a1-87371e657ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /content/drive/MyDrive/AI_TRACEFINDER_DS/artifacts_tamper_patch\n"
          ]
        }
      ],
      "source": [
        "import json, pickle, os\n",
        "ART_TP = f\"{ROOT}/artifacts_tamper_patch\"\n",
        "os.makedirs(ART_TP, exist_ok=True)\n",
        "with open(f\"{ART_TP}/patch_scaler.pkl\",\"wb\") as f: pickle.dump(scaler,f)\n",
        "with open(f\"{ART_TP}/patch_svm_sig_calibrated.pkl\",\"wb\") as f: pickle.dump(clf,f)\n",
        "with open(f\"{ART_TP}/thresholds_patch.json\",\"w\") as f: json.dump({\"global\": thr_global, \"by_domain\": thr_by_domain, \"by_type\": thr_by_type}, f)\n",
        "print(\"Saved:\", ART_TP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySn1hFHzYZFm",
        "outputId": "c7b95043-97b5-4e6a-a0d9-fca8c7d2571d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote pairs: 102 -> /content/drive/MyDrive/AI_TRACEFINDER_DS/manifests/tamper_pairs.csv\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "PAIR_CSV = f\"{ROOT}/manifests/tamper_pairs.csv\"\n",
        "os.makedirs(os.path.dirname(PAIR_CSV), exist_ok=True)\n",
        "\n",
        "orig_clean = glob.glob(f\"{TAMP_ROOT}/Original/*.tif\")\n",
        "tampered_a = glob.glob(f\"{TAMP_ROOT}/Tampered/Splicing/*.tif\")\n",
        "tampered_b = glob.glob(f\"{TAMP_ROOT}/Tampered/Copy-move/*.tif\")\n",
        "tampered_c = glob.glob(f\"{TAMP_ROOT}/Tampered/Retouching/*.tif\")\n",
        "\n",
        "def pid(p):\n",
        "    m=re.search(r\"(s\\d+_\\d+)\", os.path.basename(p))\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "orig_map = {pid(p): p for p in orig_clean}\n",
        "pairs = []\n",
        "for ttype, lst in [(\"splice\", tampered_a), (\"copy-move\", tampered_b), (\"retouch\", tampered_c)]:\n",
        "    for p in lst:\n",
        "        k = pid(p)\n",
        "        if k in orig_map:\n",
        "            pairs.append([orig_map[k], p, ttype, k])\n",
        "\n",
        "with open(PAIR_CSV, \"w\", newline=\"\") as fh:\n",
        "    csv.writer(fh).writerows([[\"clean_path\",\"tampered_path\",\"tamper_type\",\"page_id\"]] + pairs)\n",
        "print(\"Wrote pairs:\", len(pairs), \"->\", PAIR_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZtdv0pGYb1F",
        "outputId": "e4c806a5-50ee-42e6-ad12-6af27e03dfe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paired AUC (mean-delta): 0.8095238095238095\n",
            "Saved paired artifacts: /content/drive/MyDrive/AI_TRACEFINDER_DS/artifacts_tamper_pair\n"
          ]
        }
      ],
      "source": [
        "import csv, numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "def paired_patch_features(p_clean, p_tamp, limit=MAX_PATCHES, seed=42):\n",
        "    r1 = load_to_residual(p_clean); r2 = load_to_residual(p_tamp)\n",
        "    patches1 = extract_patches(r1, limit=limit, seed=seed)\n",
        "    patches2 = extract_patches(r2, limit=limit, seed=seed)\n",
        "    n = min(len(patches1), len(patches2))\n",
        "    Xd=[]\n",
        "    for i in range(n):\n",
        "        f1 = make_feat_vector(patches1[i])\n",
        "        f2 = make_feat_vector(patches2[i])\n",
        "        Xd.append(f2 - f1)\n",
        "    return np.asarray(Xd, np.float32)\n",
        "\n",
        "rows_p = list(csv.DictReader(open(PAIR_CSV)))\n",
        "X_pair, y_pair, types = [], [], []\n",
        "for r in rows_p:\n",
        "    Xd = paired_patch_features(r[\"clean_path\"], r[\"tampered_path\"], limit=MAX_PATCHES, seed=123)\n",
        "    X_pair.append(np.mean(Xd, axis=0)); y_pair.append(1); types.append(r[\"tamper_type\"])\n",
        "for r in rows_p:\n",
        "    Xd = paired_patch_features(r[\"clean_path\"], r[\"clean_path\"], limit=MAX_PATCHES, seed=456)\n",
        "    X_pair.append(np.mean(Xd, axis=0)); y_pair.append(0); types.append(\"clean\")\n",
        "\n",
        "X_pair = np.asarray(X_pair, np.float32)\n",
        "y_pair = np.asarray(y_pair, np.int64)\n",
        "types  = np.asarray(types, dtype=object)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tr_i, va_i = next(skf.split(X_pair, y_pair))\n",
        "sc_pair = StandardScaler().fit(X_pair[tr_i])\n",
        "Xp_tr = sc_pair.transform(X_pair[tr_i])\n",
        "Xp_va = sc_pair.transform(X_pair[va_i])\n",
        "\n",
        "base = SVC(kernel=\"rbf\", C=2.0, gamma=\"scale\", probability=False, class_weight=\"balanced\", random_state=42)\n",
        "pair_clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5).fit(Xp_tr, y_pair[tr_i])\n",
        "\n",
        "probs_va_pair = pair_clf.predict_proba(Xp_va)[:,1]\n",
        "print(\"Paired AUC (mean-delta):\", roc_auc_score(y_pair[va_i], probs_va_pair))\n",
        "\n",
        "# Top-k image scores per pair on validation\n",
        "import math\n",
        "def topk_mean(arr, frac=0.30):\n",
        "    n = len(arr); k = max(1, int(math.ceil(frac*n)))\n",
        "    return float(np.mean(np.sort(arr)[-k:]))\n",
        "\n",
        "def paired_patch_probs(clean_path, tampered_path, limit=MAX_PATCHES, seed=321):\n",
        "    Xd = paired_patch_features(clean_path, tampered_path, limit=limit, seed=seed)\n",
        "    Xd_s = sc_pair.transform(Xd)\n",
        "    return pair_clf.predict_proba(Xd_s)[:,1]\n",
        "\n",
        "half = len(rows_p)\n",
        "va_scores, va_labels, va_types = [], [], []\n",
        "for idx in va_i:\n",
        "    if idx < half:\n",
        "        r = rows_p[idx]\n",
        "        pc, pt, typ = r[\"clean_path\"], r[\"tampered_path\"], r[\"tamper_type\"]\n",
        "        p_img = topk_mean(paired_patch_probs(pc, pt, limit=MAX_PATCHES, seed=999), frac=0.30)\n",
        "        va_scores.append(p_img); va_labels.append(1); va_types.append(typ)\n",
        "    else:\n",
        "        ridx = idx - half\n",
        "        r = rows_p[ridx]\n",
        "        pc = r[\"clean_path\"]\n",
        "        p_img = topk_mean(paired_patch_probs(pc, pc, limit=MAX_PATCHES, seed=111), frac=0.30)\n",
        "        va_scores.append(p_img); va_labels.append(0); va_types.append(\"clean\")\n",
        "\n",
        "va_scores = np.array(va_scores, np.float32)\n",
        "va_labels = np.array(va_labels, np.int64)\n",
        "va_types  = np.array(va_types, dtype=object)\n",
        "\n",
        "# Compute per-type thresholds using Youdenâ€™s J (type vs clean)\n",
        "fpr,tpr,thr = roc_curve(va_labels, va_scores)\n",
        "thr_pair_global_topk = float(thr[int(np.argmax(tpr - fpr))])\n",
        "\n",
        "thr_pair_by_type = {}\n",
        "for typ in [\"copy-move\",\"retouch\",\"splice\"]:\n",
        "    m = (va_types==typ) | (va_types==\"clean\")\n",
        "    if m.any() and len(np.unique(va_labels[m]))==2:\n",
        "        f,t,th = roc_curve(va_labels[m], va_scores[m])\n",
        "        thr_pair_by_type[typ] = float(th[int(np.argmax(t - f))])\n",
        "\n",
        "import pickle, json, os\n",
        "ART_PAIR = f\"{ROOT}/artifacts_tamper_pair\"\n",
        "os.makedirs(ART_PAIR, exist_ok=True)\n",
        "with open(f\"{ART_PAIR}/pair_scaler.pkl\",\"wb\") as f: pickle.dump(sc_pair,f)\n",
        "with open(f\"{ART_PAIR}/pair_svm_sig.pkl\",\"wb\") as f: pickle.dump(pair_clf,f)\n",
        "with open(f\"{ART_PAIR}/pair_thresholds_topk.json\",\"w\") as f:\n",
        "    json.dump({\"global\": thr_pair_global_topk, \"by_type\": thr_pair_by_type}, f)\n",
        "print(\"Saved paired artifacts:\", ART_PAIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "V9wxg7OaYeNJ"
      },
      "outputs": [],
      "source": [
        "import os, re, glob, math, json, pickle\n",
        "import numpy as np, cv2, pywt, tensorflow as tf\n",
        "from skimage.feature import local_binary_pattern as sk_lbp\n",
        "\n",
        "# --------------------\n",
        "# Base paths and constants\n",
        "# --------------------\n",
        "ROOT = \"/content/drive/MyDrive/AI_TRACEFINDER_DS\"\n",
        "TAMP_ROOT = f\"{ROOT}/TamperedImages\"\n",
        "IMG_SIZE = (256,256)\n",
        "PATCH = 128\n",
        "STRIDE = 64\n",
        "MAX_PATCHES = 16\n",
        "\n",
        "# --------------------\n",
        "# Residual frontend and features\n",
        "# --------------------\n",
        "def load_to_residual(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Cannot read {path}\")\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA).astype(np.float32)/255.0\n",
        "    cA,(cH,cV,cD) = pywt.dwt2(img, \"haar\")\n",
        "    cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "    den = pywt.idwt2((cA,(cH,cV,cD)), \"haar\")\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "def extract_patches(res, patch=PATCH, stride=STRIDE, limit=MAX_PATCHES, seed=42):\n",
        "    H,W = res.shape\n",
        "    ys = list(range(0, H-patch+1, stride))\n",
        "    xs = list(range(0, W-patch+1, stride))\n",
        "    coords = [(y,x) for y in ys for x in xs]\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(coords)\n",
        "    coords = coords[:min(limit, len(coords))]\n",
        "    return [res[y:y+patch, x:x+patch] for y,x in coords]\n",
        "\n",
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng = float(np.ptp(img))\n",
        "    g = np.zeros_like(img, dtype=np.float32) if rng < 1e-12 else (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8 = (g * 255.0).astype(np.uint8)\n",
        "    codes = sk_lbp(g8, P=P, R=R, method=\"uniform\")\n",
        "    n_bins = P + 2\n",
        "    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "    h,w = mag.shape; cy,cx = h//2, w//2\n",
        "    yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "    bins = np.linspace(0, r.max()+1e-6, K+1)\n",
        "    feats=[]\n",
        "    for i in range(K):\n",
        "        m = (r>=bins[i]) & (r<bins[i+1]); feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return np.asarray(feats, dtype=np.float32)\n",
        "\n",
        "def residual_stats(img):\n",
        "    return np.asarray([float(img.mean()), float(img.std()), float(np.mean(np.abs(img)))], dtype=np.float32)\n",
        "\n",
        "def fft_resample_feats(img):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "    h,w = mag.shape; cy,cx = h//2, w//2\n",
        "    yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "    rmax = r.max()+1e-6\n",
        "    b1 = (r>=0.25*rmax) & (r<0.35*rmax)\n",
        "    b2 = (r>=0.35*rmax) & (r<0.50*rmax)\n",
        "    e1 = float(mag[b1].mean() if b1.any() else 0.0)\n",
        "    e2 = float(mag[b2].mean() if b2.any() else 0.0)\n",
        "    ratio = float(e2/(e1+1e-8))\n",
        "    return np.asarray([e1, e2, ratio], dtype=np.float32)\n",
        "\n",
        "def make_feat_vector(img_patch):\n",
        "    lbp = lbp_hist_safe(img_patch,8,1.0)\n",
        "    fft6 = fft_radial_energy(img_patch,6)\n",
        "    res3 = residual_stats(img_patch)\n",
        "    rsp3 = fft_resample_feats(img_patch)\n",
        "    return np.concatenate([lbp, fft6, res3, rsp3], axis=0)\n",
        "\n",
        "# --------------------\n",
        "# Objective 1: Scanner-ID artifacts (11 scanners only)\n",
        "# --------------------\n",
        "ART_SCN = ROOT\n",
        "MODEL = f\"{ART_SCN}/scanner_hybrid.keras\"\n",
        "LE_PATH = f\"{ART_SCN}/hybrid_label_encoder.pkl\"\n",
        "SCALER_PATH = f\"{ART_SCN}/hybrid_feat_scaler.pkl\"\n",
        "FPS = f\"{ART_SCN}/scanner_fingerprints.pkl\"\n",
        "FP_KEYS = f\"{ART_SCN}/fp_keys.npy\"\n",
        "\n",
        "with open(FPS,\"rb\") as f: fps_all = pickle.load(f)\n",
        "fp_keys_all = np.load(FP_KEYS, allow_pickle=True).tolist()\n",
        "\n",
        "# The valid_scanners list seems to be for a different purpose than the original model.\n",
        "# The original model was trained on all scanners present in the dataset.\n",
        "# We should use the scanner keys from the loaded fingerprint file for consistency.\n",
        "valid_scanners = fp_keys_all # Use all scanners the model was trained on\n",
        "\n",
        "fps = {k: fps_all[k] for k in fp_keys_all if k in valid_scanners}\n",
        "fp_keys = [k for k in fp_keys_all if k in valid_scanners]\n",
        "\n",
        "hyb_model = tf.keras.models.load_model(MODEL)\n",
        "with open(LE_PATH,\"rb\") as f: le_sc = pickle.load(f)\n",
        "# Filter label encoder classes based on valid_scanners if necessary,\n",
        "# but it's better to use the original classes the model was trained on.\n",
        "# le_sc.classes_ = np.array([c for c in le_sc.classes_ if c in valid_scanners])\n",
        "\n",
        "\n",
        "with open(SCALER_PATH,\"rb\") as f: sc_sc = pickle.load(f)\n",
        "n_in = int(getattr(sc_sc, \"n_features_in_\", 0))\n",
        "# The scaler expects 27 features, which is the size of the feature vector calculated below.\n",
        "# The error was due to an incorrect check for 30-D.\n",
        "if n_in != 27:\n",
        "    raise RuntimeError(f\"Loaded scaler expects {n_in} features; it must be 27-D based on model training.\")\n",
        "\n",
        "\n",
        "_dummy = np.zeros((256,256), np.float32)\n",
        "_feat = np.asarray([0]*27, np.float32).reshape(1, -1) # Change dummy feature size to 27\n",
        "_h = hyb_model.input[1].shape[-1] if isinstance(hyb_model.input, (list, tuple)) else None\n",
        "\n",
        "def corr2d(a, b):\n",
        "    a = a.astype(np.float32).ravel(); b = b.astype(np.float32).ravel()\n",
        "    a -= a.mean(); b -= b.mean()\n",
        "    d = np.linalg.norm(a)*np.linalg.norm(b)\n",
        "    return float((a @ b)/d) if d!=0 else 0.0\n",
        "\n",
        "def fft_radial_energy_img(img, K=6):\n",
        "    return fft_radial_energy(img, K=K)\n",
        "\n",
        "def make_scanner_feats(res):\n",
        "    v_corr = [corr2d(res, fps[k]) for k in fp_keys]\n",
        "    v_fft  = fft_radial_energy_img(res, K=6)\n",
        "    v_lbp  = lbp_hist_safe(res, P=8, R=1.0)\n",
        "    feat = v_corr + list(v_fft) + list(v_lbp)\n",
        "    # Ensure the feature vector is exactly 27-D (11 corr + 6 fft + 10 lbp)\n",
        "    feat = np.asarray(feat, dtype=np.float32)\n",
        "    if feat.size != 27:\n",
        "         raise RuntimeError(f\"Generated scanner feature vector size is {feat.size}, expected 27.\")\n",
        "    return sc_sc.transform(feat.reshape(1,-1))\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# Objective 2: Paired artifacts and high-recall inference\n",
        "# --------------------\n",
        "ART_PAIR = f\"{ROOT}/artifacts_tamper_pair\"\n",
        "with open(f\"{ART_PAIR}/pair_scaler.pkl\",\"rb\") as f: sc_pair = pickle.load(f)\n",
        "with open(f\"{ART_PAIR}/pair_svm_sig.pkl\",\"rb\") as f: pair_clf = pickle.load(f)\n",
        "with open(f\"{ART_PAIR}/pair_thresholds_topk.json\",\"r\") as f: THR_PAIR = json.load(f)\n",
        "\n",
        "\n",
        "orig_map = {re.search(r\"(s\\d+_\\d+)\", os.path.basename(p)).group(1): p\n",
        "            for p in glob.glob(f\"{TAMP_ROOT}/Original/*.tif\")}\n",
        "\n",
        "\n",
        "def pid_from_path(p):\n",
        "    m = re.search(r\"(s\\d+_\\d+)\", os.path.basename(p))\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "\n",
        "def paired_patch_features(p_clean, p_tamp, limit=MAX_PATCHES, seed=42):\n",
        "    r1 = load_to_residual(p_clean); r2 = load_to_residual(p_tamp)\n",
        "    patches1 = extract_patches(r1, limit=limit, seed=seed)\n",
        "    patches2 = extract_patches(r2, limit=limit, seed=seed)\n",
        "    n = min(len(patches1), len(patches2))\n",
        "    Xd=[]\n",
        "    H,W = r1.shape\n",
        "    ys = list(range(0, H-PATCH+1, STRIDE))\n",
        "    xs = list(range(0, W-PATCH+1, STRIDE))\n",
        "    coords = [(y,x) for y in ys for x in xs][:n]\n",
        "    for i in range(n):\n",
        "        f1 = make_feat_vector(patches1[i])\n",
        "        f2 = make_feat_vector(patches2[i])\n",
        "        Xd.append(f2 - f1)\n",
        "    return np.asarray(Xd, np.float32), coords\n",
        "\n",
        "\n",
        "def adjacency_hits_topk(idxs, coords):\n",
        "    S = set(idxs)\n",
        "    pos = {i: coords[i] for i in range(len(coords))}\n",
        "    adj = 0\n",
        "    for i in idxs:\n",
        "        y,x = pos[i]\n",
        "        neigh = {(y-STRIDE,x),(y+STRIDE,x),(y,x-STRIDE),(y,x+STRIDE)}\n",
        "        if any((pos[j] in neigh) for j in S if j!=i):\n",
        "            adj += 1\n",
        "    return adj\n",
        "\n",
        "\n",
        "def edge_change_score(p1, p2):\n",
        "    s1 = cv2.Sobel(p1, cv2.CV_32F, 1, 1, ksize=3)\n",
        "    s2 = cv2.Sobel(p2, cv2.CV_32F, 1, 1, ksize=3)\n",
        "    return float(np.mean(np.abs(s2) - np.abs(s1)))\n",
        "\n",
        "\n",
        "def paired_infer_type_aware(clean_path, suspect_path, tamper_type_hint=None, frac=0.30):\n",
        "    # Paired probs and coords\n",
        "    r1 = load_to_residual(clean_path)\n",
        "    r2 = load_to_residual(suspect_path)\n",
        "    patches1 = extract_patches(r1, limit=MAX_PATCHES, seed=777)\n",
        "    patches2 = extract_patches(r2, limit=MAX_PATCHES, seed=777)\n",
        "\n",
        "\n",
        "    Xd, coords = paired_patch_features(clean_path, suspect_path, limit=MAX_PATCHES, seed=777)\n",
        "    Xd_s = sc_pair.transform(Xd)\n",
        "    p_patch = pair_clf.predict_proba(Xd_s)[:,1]\n",
        "\n",
        "\n",
        "    typ = (tamper_type_hint or \"unknown\").lower()\n",
        "    thr_base = THR_PAIR[\"by_type\"].get(typ, THR_PAIR[\"global\"])\n",
        "    thr_eff = max(thr_base - 0.02, 0.0)\n",
        "\n",
        "\n",
        "    # top-k set and score\n",
        "    frac_use = 0.20 if typ == \"retouch\" else 0.30\n",
        "    n = len(p_patch); k = max(1, int(math.ceil(frac_use*n)))\n",
        "    top_idx = np.argsort(p_patch)[-k:]\n",
        "    p_img = float(np.mean(p_patch[top_idx]))\n",
        "\n",
        "\n",
        "    def hits_topk(gate): return int(np.sum(p_patch[top_idx] >= gate))\n",
        "\n",
        "\n",
        "    if typ == \"copy-move\":\n",
        "        local_gate = 0.78\n",
        "        hits = hits_topk(local_gate)\n",
        "        ok = (p_img >= (thr_eff - 0.05)) or ((p_img >= thr_eff) and (hits >= 2))\n",
        "        thr_used = thr_eff - 0.05\n",
        "\n",
        "\n",
        "    elif typ == \"retouch\":\n",
        "        # Final high-recall RT: accept p >= 0.60 outright, or require mild local evidence near thr\n",
        "        local_gate = 0.75\n",
        "        hits = hits_topk(local_gate)\n",
        "        ok = (p_img >= 0.60) or ((p_img >= max(thr_eff, 0.65)) and (hits >= 2))\n",
        "        thr_used = 0.60\n",
        "\n",
        "\n",
        "    else:\n",
        "        local_gate = 0.80\n",
        "        hits = hits_topk(local_gate)\n",
        "        ok = (p_img >= thr_base) and (hits >= 2)\n",
        "        thr_used = thr_base\n",
        "\n",
        "\n",
        "    tampered = int(ok)\n",
        "    conf = float((p_img if tampered else 1.0 - p_img)*100.0)\n",
        "    return {\"prob_tampered\": p_img,\n",
        "            \"tamper_label\": \"Tampered\" if tampered else \"Clean\",\n",
        "            \"threshold\": thr_used, \"confidence\": conf, \"hits\": hits}\n",
        "\n",
        "# --------------------\n",
        "# Objective 3: Single-image tamper detection\n",
        "# --------------------\n",
        "ART_IMG = f\"{ROOT}/artifacts_tamper_image_v1\"\n",
        "with open(f\"{ART_IMG}/image_scaler.pkl\",\"rb\") as f: sc_img = pickle.load(f)\n",
        "with open(f\"{ART_IMG}/image_svm_sig.pkl\",\"rb\") as f: img_clf = pickle.load(f)\n",
        "with open(f\"{ART_IMG}/image_thresholds.json\",\"r\") as f: THR_IMG = json.load(f)\n",
        "\n",
        "def patch_feat_single(p):\n",
        "    # This needs to match the features used for the image-level classifier\n",
        "    from skimage.feature import local_binary_pattern as sk_lbp\n",
        "    def lbp_hist_safe_single(img, P=8, R=1.0):\n",
        "        rng = float(np.ptp(img))\n",
        "        g = np.zeros_like(img, dtype=np.float32) if rng < 1e-12 else (img - float(np.min(img))) / (rng + 1e-8)\n",
        "        g8 = (g * 255.0).astype(np.uint8)\n",
        "        codes = sk_lbp(g8, P=P, R=R, method=\"uniform\")\n",
        "        n_bins = P + 2\n",
        "        hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "        return hist.astype(np.float32)\n",
        "    def fft_radial_energy_single(img, K=6):\n",
        "        f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "        h,w = mag.shape; cy,cx = h//2, w//2\n",
        "        yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "        bins = np.linspace(0, r.max()+1e-6, K+1)\n",
        "        feats=[]\n",
        "        for i in range(K):\n",
        "            m = (r>=bins[i]) & (r<bins[i+1]); feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "        return np.asarray(feats, dtype=np.float32)\n",
        "    def contrast_stat_single(img):\n",
        "        return np.asarray([float(np.std(img)) , float(np.mean(np.abs(img - np.mean(img))))], dtype=np.float32)\n",
        "\n",
        "    return np.concatenate([lbp_hist_safe_single(p,8,1.0), fft_radial_energy_single(p,6), contrast_stat_single(p)], axis=0)  # 18-D\n",
        "\n",
        "\n",
        "def infer_tamper_single(path, tamper_type_hint=None, frac=0.30):\n",
        "    res = load_to_residual(path)\n",
        "    patches = extract_patches(res, limit=MAX_PATCHES, seed=789)\n",
        "    feats = np.stack([patch_feat_single(p) for p in patches], 0) if patches else np.zeros((1,18), np.float32)\n",
        "    X_img_feat = np.mean(feats, axis=0).reshape(1,-1)\n",
        "\n",
        "    X_img_feat_scaled = sc_img.transform(X_img_feat)\n",
        "    prob = img_clf.predict_proba(X_img_feat_scaled)[:,1][0]\n",
        "\n",
        "    # Determine domain for thresholding\n",
        "    domain = \"unknown\"\n",
        "    if \"/Originals_tif/official\" in path: domain = \"orig_pdf_tif\"\n",
        "    elif \"/Originals_tif/wikipedia\" in path: domain = \"orig_pdf_tif\"\n",
        "    elif \"/TamperedImages\" in path: domain = \"tamper_dir\"\n",
        "\n",
        "    thr_base = THR_IMG[\"by_domain\"].get(domain, THR_IMG[\"global\"])\n",
        "    tampered = int(prob >= thr_base)\n",
        "    conf = float((prob if tampered else 1.0 - prob)*100.0)\n",
        "\n",
        "    # Single-image doesn't have \"hits\" or type-aware thresholds in this simple version\n",
        "    return {\"prob_tampered\": prob,\n",
        "            \"tamper_label\": \"Tampered\" if tampered else \"Clean\",\n",
        "            \"threshold\": thr_base, \"confidence\": conf,\n",
        "            \"domain\": domain, \"hits\": -1} # -1 indicates not applicable for single\n",
        "\n",
        "# --------------------\n",
        "# Unified prediction (scanner first, then tamper)\n",
        "# --------------------\n",
        "def predict_scanner_and_tamper(path, tamper_type_hint=None, frac=0.30):\n",
        "    # Scanner-ID first\n",
        "    res = load_to_residual(path)\n",
        "    x_img = np.expand_dims(res, axis=(0,-1))\n",
        "    x_ft  = make_scanner_feats(res)\n",
        "    ps = hyb_model.predict([x_img, x_ft], verbose=0).ravel()\n",
        "    s_idx = int(np.argmax(ps)); s_lab = le_sc.classes_[s_idx]; s_conf = float(ps[s_idx]*100.0)\n",
        "\n",
        "\n",
        "    # Paired if reference Original exists\n",
        "    pid = pid_from_path(path)\n",
        "    if pid and pid in orig_map:\n",
        "        r = paired_infer_type_aware(orig_map[pid], path, tamper_type_hint=tamper_type_hint, frac=frac)\n",
        "        return {\"scanner_label\": s_lab, \"scanner_confidence\": s_conf,\n",
        "                \"tamper_label\": r[\"tamper_label\"], \"tamper_probability\": r[\"prob_tampered\"],\n",
        "                \"tamper_confidence\": r[\"confidence\"], \"tamper_threshold\": r[\"threshold\"],\n",
        "                \"domain\": \"tamper_dir\", \"paired_used\": True, \"hits\": r[\"hits\"]}\n",
        "\n",
        "\n",
        "    # Fallback single-image\n",
        "    t = infer_tamper_single(path, tamper_type_hint=tamper_type_hint, frac=frac)\n",
        "    return {\"scanner_label\": s_lab, \"scanner_confidence\": s_conf,\n",
        "            \"tamper_label\": t[\"tamper_label\"], \"tamper_probability\": t[\"prob_tampered\"],\n",
        "            \"tamper_confidence\": t[\"confidence\"], \"tamper_threshold\": t[\"threshold\"],\n",
        "            \"domain\": t[\"domain\"], \"paired_used\": False, \"hits\": t[\"hits\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-mFEaaXZmcC",
        "outputId": "3425b49f-5693-4028-a4c7-5a8b1ac29c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== orig_off (2) ===\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Originals_tif/official/official/100_p1.tif -> Canon120-2 58.46% | Clean (p=0.028, thr=0.361, conf=97.2%, paired=False, hits=-1)\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Originals_tif/official/official/10_p1.tif -> Canon120-2 60.86% | Clean (p=0.035, thr=0.361, conf=96.5%, paired=False, hits=-1)\n",
            "\n",
            "=== orig_wik (2) ===\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Originals_tif/wikipedia/wikipedia/100_p1.tif -> Canon120-1 50.48% | Clean (p=0.021, thr=0.361, conf=97.9%, paired=False, hits=-1)\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/Originals_tif/wikipedia/wikipedia/101_p1.tif -> Canon120-1 50.75% | Clean (p=0.034, thr=0.361, conf=96.6%, paired=False, hits=-1)\n",
            "\n",
            "=== tdir_clean (2) ===\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Original/s11_19.tif -> HP 100.00% | Clean (p=0.371, thr=0.373, conf=62.9%, paired=True, hits=0)\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Original/s11_27.tif -> HP 99.98% | Clean (p=0.371, thr=0.373, conf=62.9%, paired=True, hits=0)\n",
            "\n",
            "=== copy (2) ===\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Tampered/Copy-move/s11_19_b.tif -> HP 100.00% | Tampered (p=0.711, thr=0.314, conf=71.1%, paired=True, hits=1)\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Tampered/Copy-move/s11_27_b.tif -> HP 99.98% | Tampered (p=0.484, thr=0.314, conf=48.4%, paired=True, hits=0)\n",
            "\n",
            "=== retouch (2) ===\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Tampered/Retouching/s11_19_c.tif -> HP 100.00% | Tampered (p=0.986, thr=0.600, conf=98.6%, paired=True, hits=2)\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Tampered/Retouching/s11_27_c.tif -> HP 99.98% | Tampered (p=0.882, thr=0.600, conf=88.2%, paired=True, hits=2)\n",
            "\n",
            "=== splice (2) ===\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Tampered/Splicing/s11_19_a.tif -> HP 100.00% | Tampered (p=0.933, thr=0.373, conf=93.3%, paired=True, hits=3)\n",
            "/content/drive/MyDrive/AI_TRACEFINDER_DS/TamperedImages/Tampered/Splicing/s11_27_a.tif -> HP 99.72% | Tampered (p=0.986, thr=0.373, conf=98.6%, paired=True, hits=3)\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "def pick_n(paths, n=5):\n",
        "    return sorted(paths)[:n]\n",
        "\n",
        "folders = {\n",
        "  \"orig_off\": glob.glob(f\"{ROOT}/Originals_tif/official/**/*.tif\", recursive=True),\n",
        "  \"orig_wik\": glob.glob(f\"{ROOT}/Originals_tif/wikipedia/**/*.tif\", recursive=True),\n",
        "  \"tdir_clean\": glob.glob(f\"{ROOT}/TamperedImages/Original/*.tif\"),\n",
        "  \"copy\": glob.glob(f\"{ROOT}/TamperedImages/Tampered/Copy-move/*.tif\"),\n",
        "  \"retouch\": glob.glob(f\"{ROOT}/TamperedImages/Tampered/Retouching/*.tif\"),\n",
        "  \"splice\": glob.glob(f\"{ROOT}/TamperedImages/Tampered/Splicing/*.tif\"),\n",
        "}\n",
        "\n",
        "samples = {k: pick_n(v, 2) for k,v in folders.items()}\n",
        "\n",
        "for group, plist in samples.items():\n",
        "    print(f\"\\n=== {group} ({len(plist)}) ===\")\n",
        "    for p in plist:\n",
        "        hint = None\n",
        "        if group==\"copy\": hint=\"copy-move\"\n",
        "        elif group==\"retouch\": hint=\"retouch\"\n",
        "        elif group==\"splice\": hint=\"splice\"\n",
        "        r = predict_scanner_and_tamper(p, tamper_type_hint=hint, frac=0.30)\n",
        "        print(f\"{p} -> {r['scanner_label']} {r['scanner_confidence']:.2f}% | \"\n",
        "              f\"{r['tamper_label']} (p={r['tamper_probability']:.3f}, thr={r['tamper_threshold']:.3f}, \"\n",
        "              f\"conf={r['tamper_confidence']:.1f}%, paired={r['paired_used']}, hits={r['hits']})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kWwO7FO7bE3R"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=(256,256); PATCH=128; STRIDE=64; MAX_PATCHES=16\n",
        "\n",
        "def load_to_residual(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None: raise ValueError(f\"Cannot read {path}\")\n",
        "    if img.ndim == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA).astype(np.float32)/255.0\n",
        "    cA,(cH,cV,cD) = pywt.dwt2(img, \"haar\")\n",
        "    cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "    den = pywt.idwt2((cA,(cH,cV,cD)), \"haar\")\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "def extract_patches(res, patch=PATCH, stride=STRIDE, limit=MAX_PATCHES, seed=42):\n",
        "    H,W = res.shape\n",
        "    ys = list(range(0, H-patch+1, stride)); xs = list(range(0, W-patch+1, stride))\n",
        "    coords = [(y,x) for y in ys for x in xs]\n",
        "    rng = np.random.RandomState(seed); rng.shuffle(coords)\n",
        "    coords = coords[:min(limit, len(coords))]\n",
        "    return [res[y:y+patch, x:x+patch] for y,x in coords]\n",
        "\n",
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng = float(np.ptp(img))\n",
        "    g = np.zeros_like(img, dtype=np.float32) if rng < 1e-12 else (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8 = (g * 255.0).astype(np.uint8)\n",
        "    codes = sk_lbp(g8, P=P, R=R, method=\"uniform\")\n",
        "    n_bins = P + 2\n",
        "    hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "    h,w = mag.shape; cy,cx = h//2, w//2\n",
        "    yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "    bins = np.linspace(0, r.max()+1e-6, K+1)\n",
        "    feats=[]\n",
        "    for i in range(K):\n",
        "        m = (r>=bins[i]) & (r<bins[i+1]); feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return np.asarray(feats, dtype=np.float32)\n",
        "\n",
        "def residual_stats(img):\n",
        "    return np.asarray([float(img.mean()), float(img.std()), float(np.mean(np.abs(img)))], dtype=np.float32)\n",
        "\n",
        "def fft_resample_feats(img):\n",
        "    f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "    h,w = mag.shape; cy,cx = h//2, w//2\n",
        "    yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "    rmax = r.max()+1e-6\n",
        "    b1 = (r>=0.25*rmax) & (r<0.35*rmax)\n",
        "    b2 = (r>=0.35*rmax) & (r<0.50*rmax)\n",
        "    e1 = float(mag[b1].mean() if b1.any() else 0.0)\n",
        "    e2 = float(mag[b2].mean() if b2.any() else 0.0)\n",
        "    ratio = float(e2/(e1+1e-8))\n",
        "    return np.asarray([e1, e2, ratio], dtype=np.float32)\n",
        "\n",
        "def make_feat_vector(img_patch):\n",
        "    lbp = lbp_hist_safe(img_patch,8,1.0)\n",
        "    fft6 = fft_radial_energy(img_patch,6)\n",
        "    res3 = residual_stats(img_patch)\n",
        "    rsp3 = fft_resample_feats(img_patch)\n",
        "    return np.concatenate([lbp, fft6, res3, rsp3], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0Ls2fhmbZEt",
        "outputId": "c0df1a2d-adfc-42e6-f09d-39113a918cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patch-level AUC: 0.9268257567577295\n",
            "Saved patch artifacts: /content/drive/MyDrive/AI_TRACEFINDER_DS/artifacts_tamper_patch\n"
          ]
        }
      ],
      "source": [
        "import csv, numpy as np\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import json, pickle, os\n",
        "\n",
        "with open(MANIFEST_CSV,\"r\") as fh:\n",
        "    rr = list(csv.DictReader(fh))\n",
        "\n",
        "if len(rr) <= 1:\n",
        "    raise SystemExit(\"Manifest empty â€” ensure TIFFs are in Originals_tif and Tampered images, then rerun Block 2.\")\n",
        "\n",
        "paths  = np.array([r[\"path\"] for r in rr], dtype=object)\n",
        "labels = np.array([int(r[\"label\"]) for r in rr], dtype=np.int64)\n",
        "groups = np.array([r[\"page_id\"] for r in rr], dtype=object)\n",
        "domain = np.array([r[\"domain\"] for r in rr], dtype=object)\n",
        "ttype  = np.array([r[\"tamper_type\"] for r in rr], dtype=object)\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tr_idx, va_idx = next(sgkf.split(paths, labels, groups))\n",
        "\n",
        "def build_patchset(idxs, balance_clean_domains=True, seed=42, aug_clean_tdir=True):\n",
        "    Xp, yp, dp, tp, gp, ip = [], [], [], [], [], []\n",
        "    rng = np.random.RandomState(seed)\n",
        "    idxs_clean = [i for i in idxs if labels[i]==0]\n",
        "    idxs_clean_orig = [i for i in idxs_clean if domain[i]==\"orig_pdf_tif\"]\n",
        "    idxs_clean_tdir = [i for i in idxs_clean if domain[i]==\"tamper_dir\"]\n",
        "    if balance_clean_domains and len(idxs_clean_orig)>0 and len(idxs_clean_tdir)>0:\n",
        "        cap = min(len(idxs_clean_orig), len(idxs_clean_tdir))\n",
        "        rng.shuffle(idxs_clean_orig); rng.shuffle(idxs_clean_tdir)\n",
        "        idxs_use = idxs_clean_orig[:cap] + idxs_clean_tdir[:cap] + [i for i in idxs if labels[i]==1]\n",
        "    else:\n",
        "        idxs_use = list(idxs)\n",
        "    for i in idxs_use:\n",
        "        res = load_to_residual(paths[i])\n",
        "        patches = extract_patches(res, limit=MAX_PATCHES, seed=(seed+i)%10000)\n",
        "        for pch in patches:\n",
        "            if aug_clean_tdir and labels[i]==0 and domain[i]==\"tamper_dir\":\n",
        "                pch = np.clip(pch + 0.003*np.random.randn(*pch.shape), 0, 1).astype(np.float32)\n",
        "            Xp.append(make_feat_vector(pch))\n",
        "            yp.append(labels[i]); dp.append(domain[i]); tp.append(ttype[i]); gp.append(groups[i]); ip.append(paths[i])\n",
        "    return np.asarray(Xp, np.float32), np.asarray(yp, np.int64), np.array(dp, dtype=object), np.array(tp, dtype=object), np.array(gp, dtype=object), np.array(ip, dtype=object)\n",
        "\n",
        "Xtr, ytr, dtr, ttr, gtr, itr = build_patchset(tr_idx, balance_clean_domains=True, aug_clean_tdir=True)\n",
        "Xva, yva, dva, tva, gva, iva = build_patchset(va_idx, balance_clean_domains=False, aug_clean_tdir=False)\n",
        "\n",
        "scaler = StandardScaler().fit(Xtr)\n",
        "Xs_tr = scaler.transform(Xtr)\n",
        "Xs_va = scaler.transform(Xva)\n",
        "\n",
        "base = SVC(kernel=\"rbf\", C=2.0, gamma=\"scale\", probability=False, class_weight=\"balanced\", random_state=42)\n",
        "clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5).fit(Xs_tr, ytr)\n",
        "\n",
        "probs_va = clf.predict_proba(Xs_va)[:,1]\n",
        "auc_patch = roc_auc_score(yva, probs_va)\n",
        "print(\"Patch-level AUC:\", auc_patch)\n",
        "\n",
        "def best_thr(y, p):\n",
        "    fpr,tpr,thr = roc_curve(y, p)\n",
        "    j = tpr - fpr\n",
        "    return float(thr[int(np.argmax(j))])\n",
        "\n",
        "thr_global = best_thr(yva, probs_va)\n",
        "\n",
        "thr_by_domain = {}\n",
        "for dom in [\"orig_pdf_tif\",\"tamper_dir\"]:\n",
        "    m = (dva==dom)\n",
        "    if m.any() and len(np.unique(yva[m]))==2:\n",
        "        thr_by_domain[dom] = best_thr(yva[m], probs_va[m])\n",
        "\n",
        "thr_by_type = {}\n",
        "for t in [\"copy-move\",\"retouch\",\"splice\"]:\n",
        "    m = (tva==t) | (tva==\"clean\")\n",
        "    if m.any() and len(np.unique(yva[m]))==2:\n",
        "        thr_by_type[t] = best_thr(yva[m], probs_va[m])\n",
        "\n",
        "ART_TP = f\"{ROOT}/artifacts_tamper_patch\"\n",
        "os.makedirs(ART_TP, exist_ok=True)\n",
        "with open(f\"{ART_TP}/patch_scaler.pkl\",\"wb\") as f: pickle.dump(scaler,f)\n",
        "with open(f\"{ART_TP}/patch_svm_sig_calibrated.pkl\",\"wb\") as f: pickle.dump(clf,f)\n",
        "with open(f\"{ART_TP}/thresholds_patch.json\",\"w\") as f: json.dump({\"global\": thr_global, \"by_domain\": thr_by_domain, \"by_type\": thr_by_type}, f)\n",
        "print(\"Saved patch artifacts:\", ART_TP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PqQ0JS_bi0r",
        "outputId": "5f3538d4-4ef8-469b-f0f0-3e0a7975bd7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote pairs: 102\n",
            "Paired AUC: 0.8095238095238095\n",
            "Saved paired artifacts: /content/drive/MyDrive/AI_TRACEFINDER_DS/artifacts_tamper_pair\n"
          ]
        }
      ],
      "source": [
        "import re, json, pickle\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "PAIR_CSV = f\"{ROOT}/manifests/tamper_pairs.csv\"\n",
        "os.makedirs(os.path.dirname(PAIR_CSV), exist_ok=True)\n",
        "\n",
        "orig_clean = glob.glob(f\"{TAMP_ROOT}/Original/*.tif\")\n",
        "tampered_a = glob.glob(f\"{TAMP_ROOT}/Tampered/Splicing/*.tif\")\n",
        "tampered_b = glob.glob(f\"{TAMP_ROOT}/Tampered/Copy-move/*.tif\")\n",
        "tampered_c = glob.glob(f\"{TAMP_ROOT}/Tampered/Retouching/*.tif\")\n",
        "\n",
        "def pid(p):\n",
        "    m=re.search(r\"(s\\d+_\\d+)\", os.path.basename(p))\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "orig_map = {pid(p): p for p in orig_clean}\n",
        "pairs = []\n",
        "for ttype, lst in [(\"splice\", tampered_a), (\"copy-move\", tampered_b), (\"retouch\", tampered_c)]:\n",
        "    for p in lst:\n",
        "        k = pid(p)\n",
        "        if k in orig_map:\n",
        "            pairs.append([orig_map[k], p, ttype, k])\n",
        "\n",
        "with open(PAIR_CSV, \"w\", newline=\"\") as fh:\n",
        "    csv.writer(fh).writerows([[\"clean_path\",\"tampered_path\",\"tamper_type\",\"page_id\"]] + pairs)\n",
        "print(\"Wrote pairs:\", len(pairs))\n",
        "\n",
        "def paired_patch_features(p_clean, p_tamp, limit=MAX_PATCHES, seed=42):\n",
        "    r1 = load_to_residual(p_clean); r2 = load_to_residual(p_tamp)\n",
        "    patches1 = extract_patches(r1, limit=limit, seed=seed)\n",
        "    patches2 = extract_patches(r2, limit=limit, seed=seed)\n",
        "    n = min(len(patches1), len(patches2))\n",
        "    Xd=[]\n",
        "    for i in range(n):\n",
        "        f1 = make_feat_vector(patches1[i]); f2 = make_feat_vector(patches2[i])\n",
        "        Xd.append(f2 - f1)\n",
        "    return np.asarray(Xd, np.float32)\n",
        "\n",
        "rows_p = list(csv.DictReader(open(PAIR_CSV)))\n",
        "X_pair, y_pair, types = [], [], []\n",
        "for r in rows_p:\n",
        "    Xd = paired_patch_features(r[\"clean_path\"], r[\"tampered_path\"], limit=MAX_PATCHES, seed=123)\n",
        "    X_pair.append(np.mean(Xd, axis=0)); y_pair.append(1); types.append(r[\"tamper_type\"])\n",
        "for r in rows_p:\n",
        "    Xd = paired_patch_features(r[\"clean_path\"], r[\"clean_path\"], limit=MAX_PATCHES, seed=456)\n",
        "    X_pair.append(np.mean(Xd, axis=0)); y_pair.append(0); types.append(\"clean\")\n",
        "\n",
        "X_pair = np.asarray(X_pair, np.float32); y_pair = np.asarray(y_pair, np.int64); types = np.asarray(types, dtype=object)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tr_i, va_i = next(skf.split(X_pair, y_pair))\n",
        "sc_pair = StandardScaler().fit(X_pair[tr_i])\n",
        "Xp_tr = sc_pair.transform(X_pair[tr_i]); Xp_va = sc_pair.transform(X_pair[va_i])\n",
        "\n",
        "base = SVC(kernel=\"rbf\", C=2.0, gamma=\"scale\", probability=False, class_weight=\"balanced\", random_state=42)\n",
        "pair_clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5).fit(Xp_tr, y_pair[tr_i])\n",
        "\n",
        "probs_va_pair = pair_clf.predict_proba(Xp_va)[:,1]\n",
        "print(\"Paired AUC:\", roc_auc_score(y_pair[va_i], probs_va_pair))\n",
        "\n",
        "# Compute top-k image thresholds (use mean as proxy in this export; app uses top-k per image)\n",
        "def best_thr(y, p):\n",
        "    fpr,tpr,thr = roc_curve(y, p)\n",
        "    return float(thr[int(np.argmax(tpr - fpr))])\n",
        "\n",
        "thr_pair_global_topk = best_thr(y_pair[va_i], probs_va_pair)\n",
        "\n",
        "thr_pair_by_type = {}\n",
        "for typ in [\"copy-move\",\"retouch\",\"splice\"]:\n",
        "    m = (types[va_i]==typ) | (types[va_i]==\"clean\")\n",
        "    if m.any():\n",
        "        yv = y_pair[va_i][m]; pv = probs_va_pair[m]\n",
        "        thr_pair_by_type[typ] = best_thr(yv, pv)\n",
        "\n",
        "ART_PAIR = f\"{ROOT}/artifacts_tamper_pair\"\n",
        "os.makedirs(ART_PAIR, exist_ok=True)\n",
        "with open(f\"{ART_PAIR}/pair_scaler.pkl\",\"wb\") as f: pickle.dump(sc_pair,f)\n",
        "with open(f\"{ART_PAIR}/pair_svm_sig.pkl\",\"wb\") as f: pickle.dump(pair_clf,f)\n",
        "with open(f\"{ART_PAIR}/pair_thresholds_topk.json\",\"w\") as f:\n",
        "    json.dump({\"global\": thr_pair_global_topk, \"by_type\": thr_pair_by_type}, f)\n",
        "print(\"Saved paired artifacts:\", ART_PAIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCHsOAoEbo6a",
        "outputId": "97bb2b15-ab69-4763-9e17-e006f1c5b3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patch-level AUC: 0.9267777657800333\n",
            "Saved patch artifacts: /content/drive/MyDrive/AI_TRACEFINDER_DS/artifacts_tamper_patch\n"
          ]
        }
      ],
      "source": [
        "# Save single-image patch artifacts (run if not already saved)\n",
        "import csv, json, pickle, os, numpy as np\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "MANIFEST_CSV = f\"{ROOT}/manifests/tamper_manifest_grouped.csv\"\n",
        "\n",
        "with open(MANIFEST_CSV,\"r\") as fh:\n",
        "    rr = list(csv.DictReader(fh))\n",
        "\n",
        "paths  = np.array([r[\"path\"] for r in rr], dtype=object)\n",
        "labels = np.array([int(r[\"label\"]) for r in rr], dtype=np.int64)\n",
        "groups = np.array([r[\"page_id\"] for r in rr], dtype=object)\n",
        "domain = np.array([r[\"domain\"] for r in rr], dtype=object)\n",
        "ttype  = np.array([r[\"tamper_type\"] for r in rr], dtype=object)\n",
        "\n",
        "IMG_SIZE=(256,256); PATCH=128; STRIDE=64; MAX_PATCHES=16\n",
        "\n",
        "def build_patchset(idxs, balance_clean_domains=True, seed=42, aug_clean_tdir=True):\n",
        "    Xp, yp, dp, tp, gp, ip = [], [], [], [], [], []\n",
        "    rng = np.random.RandomState(seed)\n",
        "    idxs_clean = [i for i in idxs if labels[i]==0]\n",
        "    idxs_clean_orig = [i for i in idxs_clean if domain[i]==\"orig_pdf_tif\"]\n",
        "    idxs_clean_tdir = [i for i in idxs_clean if domain[i]==\"tamper_dir\"]\n",
        "    if balance_clean_domains and len(idxs_clean_orig)>0 and len(idxs_clean_tdir)>0:\n",
        "        cap = min(len(idxs_clean_orig), len(idxs_clean_tdir))\n",
        "        rng.shuffle(idxs_clean_orig); rng.shuffle(idxs_clean_tdir)\n",
        "        idxs_use = idxs_clean_orig[:cap] + idxs_clean_tdir[:cap] + [i for i in idxs if labels[i]==1]\n",
        "    else:\n",
        "        idxs_use = list(idxs)\n",
        "    for i in idxs_use:\n",
        "        import cv2, pywt\n",
        "        def load_to_residual(path):\n",
        "            img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "            if img is None: raise ValueError(f\"Cannot read {path}\")\n",
        "            if img.ndim == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA).astype(np.float32)/255.0\n",
        "            cA,(cH,cV,cD) = pywt.dwt2(img, \"haar\")\n",
        "            cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "            den = pywt.idwt2((cA,(cH,cV,cD)), \"haar\")\n",
        "            return (img - den).astype(np.float32)\n",
        "        def extract_patches(res, patch=PATCH, stride=STRIDE, limit=MAX_PATCHES, seed=42):\n",
        "            H,W = res.shape\n",
        "            ys = list(range(0, H-patch+1, stride)); xs = list(range(0, W-patch+1, stride))\n",
        "            coords = [(y,x) for y in ys for x in xs]\n",
        "            rng = np.random.RandomState(seed); rng.shuffle(coords)\n",
        "            coords = coords[:min(limit, len(coords))]\n",
        "            return [res[y:y+patch, x:x+patch] for y,x in coords]\n",
        "        from skimage.feature import local_binary_pattern as sk_lbp\n",
        "        def lbp_hist_safe(img, P=8, R=1.0):\n",
        "            rngv = float(np.ptp(img))\n",
        "            g = np.zeros_like(img, dtype=np.float32) if rngv < 1e-12 else (img - float(np.min(img))) / (rngv + 1e-8)\n",
        "            g8 = (g * 255.0).astype(np.uint8)\n",
        "            codes = sk_lbp(g8, P=P, R=R, method=\"uniform\")\n",
        "            n_bins = P + 2\n",
        "            hist, _ = np.histogram(codes, bins=np.arange(n_bins+1), density=True)\n",
        "            return hist.astype(np.float32)\n",
        "        def fft_radial_energy(img, K=6):\n",
        "            f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "            h,w = mag.shape; cy,cx = h//2, w//2\n",
        "            yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "            bins = np.linspace(0, r.max()+1e-6, K+1)\n",
        "            feats=[]\n",
        "            for i in range(K):\n",
        "                m = (r>=bins[i]) & (r<bins[i+1]); feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "            return np.asarray(feats, dtype=np.float32)\n",
        "        def residual_stats(img):\n",
        "            return np.asarray([float(img.mean()), float(img.std()), float(np.mean(np.abs(img)))], dtype=np.float32)\n",
        "        def fft_resample_feats(img):\n",
        "            f = np.fft.fftshift(np.fft.fft2(img)); mag = np.abs(f)\n",
        "            h,w = mag.shape; cy,cx = h//2, w//2\n",
        "            yy,xx = np.ogrid[:h,:w]; r = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
        "            rmax = r.max()+1e-6\n",
        "            b1 = (r>=0.25*rmax) & (r<0.35*rmax)\n",
        "            b2 = (r>=0.35*rmax) & (r<0.50*rmax)\n",
        "            e1 = float(mag[b1].mean() if b1.any() else 0.0)\n",
        "            e2 = float(mag[b2].mean() if b2.any() else 0.0)\n",
        "            ratio = float(e2/(e1+1e-8))\n",
        "            return np.asarray([e1, e2, ratio], dtype=np.float32)\n",
        "        def make_feat_vector(img_patch):\n",
        "            return np.concatenate([lbp_hist_safe(img_patch,8,1.0),\n",
        "                                   fft_radial_energy(img_patch,6),\n",
        "                                   residual_stats(img_patch),\n",
        "                                   fft_resample_feats(img_patch)], axis=0)\n",
        "        res = load_to_residual(paths[i])\n",
        "        patches = extract_patches(res, limit=MAX_PATCHES, seed=(seed+i)%10000)\n",
        "        for pch in patches:\n",
        "            if aug_clean_tdir and labels[i]==0 and domain[i]==\"tamper_dir\":\n",
        "                pch = np.clip(pch + 0.003*np.random.randn(*pch.shape), 0, 1).astype(np.float32)\n",
        "            Xp.append(make_feat_vector(pch))\n",
        "            yp.append(labels[i]); dp.append(domain[i]); tp.append(ttype[i]); gp.append(groups[i]); ip.append(paths[i])\n",
        "    return np.asarray(Xp, np.float32), np.asarray(yp, np.int64), np.array(dp, dtype=object), np.array(tp, dtype=object), np.array(gp, dtype=object), np.array(ip, dtype=object)\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tr_idx, va_idx = next(sgkf.split(paths, labels, groups))\n",
        "Xtr, ytr, dtr, ttr, gtr, itr = build_patchset(tr_idx, balance_clean_domains=True, aug_clean_tdir=True)\n",
        "Xva, yva, dva, tva, gva, iva = build_patchset(va_idx, balance_clean_domains=False, aug_clean_tdir=False)\n",
        "\n",
        "scaler = StandardScaler().fit(Xtr)\n",
        "Xs_tr = scaler.transform(Xtr)\n",
        "Xs_va = scaler.transform(Xva)\n",
        "\n",
        "base = SVC(kernel=\"rbf\", C=2.0, gamma=\"scale\", probability=False, class_weight=\"balanced\", random_state=42)\n",
        "clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5).fit(Xs_tr, ytr)\n",
        "\n",
        "probs_va = clf.predict_proba(Xs_va)[:,1]\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "print(\"Patch-level AUC:\", roc_auc_score(yva, probs_va))\n",
        "\n",
        "def best_thr(y, p):\n",
        "    fpr,tpr,thr = roc_curve(y, p)\n",
        "    j = tpr - fpr\n",
        "    return float(thr[int(np.argmax(j))])\n",
        "\n",
        "thr_global = best_thr(yva, probs_va)\n",
        "thr_by_domain, thr_by_type = {}, {}\n",
        "for dom in [\"orig_pdf_tif\",\"tamper_dir\"]:\n",
        "    m = (dva==dom)\n",
        "    if m.any() and len(np.unique(yva[m]))==2:\n",
        "        thr_by_domain[dom] = best_thr(yva[m], probs_va[m])\n",
        "\n",
        "for t in [\"copy-move\",\"retouch\",\"splice\"]:\n",
        "    m = (tva==t) | (tva==\"clean\")\n",
        "    if m.any() and len(np.unique(yva[m]))==2:\n",
        "        thr_by_type[t] = best_thr(yva[m], probs_va[m])\n",
        "\n",
        "ART_TP = f\"{ROOT}/artifacts_tamper_patch\"\n",
        "os.makedirs(ART_TP, exist_ok=True)\n",
        "with open(f\"{ART_TP}/patch_scaler.pkl\",\"wb\") as f: pickle.dump(scaler,f)\n",
        "with open(f\"{ART_TP}/patch_svm_sig_calibrated.pkl\",\"wb\") as f: pickle.dump(clf,f)\n",
        "with open(f\"{ART_TP}/thresholds_patch.json\",\"w\") as f: json.dump({\"global\": thr_global, \"by_domain\": thr_by_domain, \"by_type\": thr_by_type}, f)\n",
        "\n",
        "print(\"Saved patch artifacts:\", ART_TP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1sUNhA-OiZx",
        "outputId": "1f25365d-5cfd-4774-8f40-d1bb5726d4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy (image): 0.8978\n",
            "Test accuracy (image): 0.9000\n",
            "Classification report (image):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Clean       1.00      0.86      0.92        49\n",
            "    Tampered       0.75      1.00      0.86        21\n",
            "\n",
            "    accuracy                           0.90        70\n",
            "   macro avg       0.88      0.93      0.89        70\n",
            "weighted avg       0.93      0.90      0.90        70\n",
            "\n",
            "Confusion matrix (image):\n",
            " [[42  7]\n",
            " [ 0 21]]\n",
            "Image-level AUC: 0.9252\n",
            "âœ… Saved image-level artifacts: /content/drive/MyDrive/AI_TRACEFINDER_DS/artifacts_tamper_image_v1\n"
          ]
        }
      ],
      "source": [
        "# Image-level tamper classifier: average 18-D patch features per image; calibrated RBF-SVM with group split.\n",
        "\n",
        "import os, csv, json, pickle, numpy as np, cv2, pywt, math, re\n",
        "from skimage.feature import local_binary_pattern as sk_lbp\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "\n",
        "MANIFEST_CSV = f\"{ROOT}/manifests/tamper_manifest_grouped.csv\"\n",
        "ART_IMG = f\"{ROOT}/artifacts_tamper_image_v1\"\n",
        "os.makedirs(ART_IMG, exist_ok=True)\n",
        "\n",
        "IMG_SIZE=(256,256); PATCH=128; STRIDE=64; MAX_PATCHES=16  # extract more patches but aggregate by mean\n",
        "\n",
        "def load_to_residual(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None: raise ValueError(f\"Cannot read {path}\")\n",
        "    if img.ndim == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA).astype(np.float32)/255.0\n",
        "    cA,(cH,cV,cD)=pywt.dwt2(img,\"haar\"); cH.fill(0); cV.fill(0); cD.fill(0)\n",
        "    den=pywt.idwt2((cA,(cH,cV,cD)),\"haar\")\n",
        "    return (img - den).astype(np.float32)\n",
        "\n",
        "def extract_patches(res, patch=PATCH, stride=STRIDE, limit=MAX_PATCHES, seed=42):\n",
        "    H,W=res.shape\n",
        "    ys=list(range(0,H-patch+1,stride)); xs=list(range(0,W-patch+1,stride))\n",
        "    coords=[(y,x) for y in ys for x in xs]\n",
        "    rng=np.random.RandomState(seed); rng.shuffle(coords)\n",
        "    coords=coords[:min(limit, len(coords))]\n",
        "    return [res[y:y+patch, x:x+patch] for y,x in coords]\n",
        "\n",
        "def lbp_hist_safe(img, P=8, R=1.0):\n",
        "    rng=float(np.ptp(img))\n",
        "    g=np.zeros_like(img, dtype=np.float32) if rng<1e-12 else (img - float(np.min(img))) / (rng + 1e-8)\n",
        "    g8=(g*255.0).astype(np.uint8)\n",
        "    codes=sk_lbp(g8,P=P,R=R,method=\"uniform\")\n",
        "    n_bins=P+2\n",
        "    hist,_=np.histogram(codes,bins=np.arange(n_bins+1),density=True)\n",
        "    return hist.astype(np.float32)\n",
        "\n",
        "def fft_radial_energy(img, K=6):\n",
        "    f=np.fft.fftshift(np.fft.fft2(img)); mag=np.abs(f)\n",
        "    h,w=mag.shape; cy,cx=h//2,w//2\n",
        "    yy,xx=np.ogrid[:h,:w]; r=np.sqrt((yy-cy)**2+(xx-cx)**2)\n",
        "    bins=np.linspace(0,r.max()+1e-6,K+1)\n",
        "    feats=[]\n",
        "    for i in range(K):\n",
        "        m=(r>=bins[i])&(r<bins[i+1]); feats.append(float(mag[m].mean() if m.any() else 0.0))\n",
        "    return np.asarray(feats, dtype=np.float32)\n",
        "\n",
        "def contrast_stat(img):\n",
        "    return np.asarray([float(np.std(img)) , float(np.mean(np.abs(img - np.mean(img))))], dtype=np.float32)\n",
        "\n",
        "def patch_feat(p):\n",
        "    return np.concatenate([lbp_hist_safe(p,8,1.0), fft_radial_energy(p,6), contrast_stat(p)], axis=0)  # 18-D\n",
        "\n",
        "with open(MANIFEST_CSV,\"r\") as fh:\n",
        "    rr=list(csv.DictReader(fh))\n",
        "paths  = np.array([r[\"path\"] for r in rr], dtype=object)\n",
        "labels = np.array([int(r[\"label\"]) for r in rr], dtype=np.int64)\n",
        "groups = np.array([r[\"page_id\"] for r in rr], dtype=object)\n",
        "domain = np.array([r[\"domain\"] for r in rr], dtype=object)\n",
        "ttype  = np.array([r[\"tamper_type\"] for r in rr], dtype=object)\n",
        "\n",
        "# Build image-level features by averaging 16â€“20 patches (robust mean)\n",
        "X_img, y_img, d_img, g_img, t_img, p_img = [], [], [], [], [], []\n",
        "for i, pth in enumerate(paths):\n",
        "    res = load_to_residual(pth)\n",
        "    patches = extract_patches(res, limit=MAX_PATCHES, seed=1234 + i)\n",
        "    feats = np.stack([patch_feat(p) for p in patches], 0) if patches else np.zeros((1,18), np.float32)\n",
        "    X_img.append(np.mean(feats, axis=0))\n",
        "    y_img.append(labels[i])\n",
        "    d_img.append(domain[i])\n",
        "    g_img.append(groups[i])\n",
        "    t_img.append(ttype[i])\n",
        "    p_img.append(pth)\n",
        "\n",
        "X_img = np.asarray(X_img, np.float32)\n",
        "y_img = np.asarray(y_img, np.int64)\n",
        "d_img = np.asarray(d_img, dtype=object)\n",
        "g_img = np.asarray(g_img, dtype=object)\n",
        "t_img = np.asarray(t_img, dtype=object)\n",
        "p_img = np.asarray(p_img, dtype=object)\n",
        "\n",
        "# Group split at image level\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "tr_i, va_i = next(sgkf.split(X_img, y_img, g_img))\n",
        "\n",
        "scaler = StandardScaler().fit(X_img[tr_i])\n",
        "Xt = scaler.transform(X_img[tr_i])\n",
        "Xv = scaler.transform(X_img[va_i])\n",
        "\n",
        "base = SVC(kernel=\"rbf\", C=0.8, gamma=\"scale\", probability=False, class_weight=\"balanced\", random_state=42)\n",
        "clf  = CalibratedClassifierCV(base, method=\"sigmoid\", cv=10).fit(Xt, y_img[tr_i])\n",
        "\n",
        "# Metrics (image-level)\n",
        "ytr_pred = clf.predict(Xt); yva_pred = clf.predict(Xv)\n",
        "print(\"Train accuracy (image):\", f\"{accuracy_score(y_img[tr_i], ytr_pred):.4f}\")\n",
        "print(\"Test accuracy (image):\",  f\"{accuracy_score(y_img[va_i], yva_pred):.4f}\")\n",
        "print(\"Classification report (image):\\n\", classification_report(y_img[va_i], yva_pred, target_names=[\"Clean\",\"Tampered\"], zero_division=0))\n",
        "print(\"Confusion matrix (image):\\n\", confusion_matrix(y_img[va_i], yva_pred, labels=[0,1]))\n",
        "\n",
        "probs_va = clf.predict_proba(Xv)[:,1]\n",
        "print(\"Image-level AUC:\", f\"{roc_auc_score(y_img[va_i], probs_va):.4f}\")\n",
        "\n",
        "def best_thr(y, p):\n",
        "    fpr,tpr,thr = roc_curve(y, p)\n",
        "    j = tpr - fpr\n",
        "    return float(thr[int(np.argmax(j))])\n",
        "\n",
        "thr_global = best_thr(y_img[va_i], probs_va)\n",
        "thr_by_domain = {}\n",
        "for dom in [\"orig_pdf_tif\",\"tamper_dir\"]:\n",
        "    m = (d_img[va_i]==dom)\n",
        "    if m.any() and len(np.unique(y_img[va_i][m]))==2:\n",
        "        thr_by_domain[dom] = best_thr(y_img[va_i][m], probs_va[m])\n",
        "\n",
        "# Domain offsets (retain)\n",
        "if \"tamper_dir\" in thr_by_domain:\n",
        "    thr_by_domain[\"tamper_dir\"] = float(min(1.0, thr_by_domain[\"tamper_dir\"] + 0.03))\n",
        "\n",
        "with open(f\"{ART_IMG}/image_scaler.pkl\",\"wb\") as f: pickle.dump(scaler,f)\n",
        "with open(f\"{ART_IMG}/image_svm_sig.pkl\",\"wb\") as f: pickle.dump(clf,f)\n",
        "with open(f\"{ART_IMG}/image_thresholds.json\",\"w\") as f: json.dump({\"global\": thr_global, \"by_domain\": thr_by_domain}, f)\n",
        "print(\"âœ… Saved image-level artifacts:\", ART_IMG)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
